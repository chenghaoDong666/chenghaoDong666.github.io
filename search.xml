<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>python学习</title>
      <link href="python-xue-xi/"/>
      <url>python-xue-xi/</url>
      
        <content type="html"><![CDATA[<p>格式化输出，文字和数字等混合输出时使用！</p><pre class=" language-python"><code class="language-python"><span class="token string">"Skipping {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span></code></pre><p>文件读取</p><p><a href="https://www.cnblogs.com/ymjyqsx/p/6554817.html">https://www.cnblogs.com/ymjyqsx/p/6554817.html</a></p><p>with open as f 为了保证无论是否出错都能正确地关闭文件</p><pre class=" language-python"><code class="language-python"><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"locs.txt"</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#f.write(fname+"\n")</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#每个line都是str</span>        linelist<span class="token operator">=</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#字符串切割</span></code></pre><p>split():str.split(str=””, num=string.count(str))</p><p>str –分隔符，默认为所有的空字符，包括空格、换行(\n)、制表符(\t)等。</p><p>num – 分割次数。默认为 -1, 即分隔所有。</p><p>返回分割后的字符串列表。</p><p>进度条</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm<span class="token keyword">for</span> fname <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>input_dir<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span></code></pre><p>绝对路径和相对路径</p><p><a href="https://blog.csdn.net/databatman/article/details/49453953">https://blog.csdn.net/databatman/article/details/49453953</a></p><p>strip():</p><p><strong>strip()</strong> 处理的时候，如果不带参数，默认是清除两边的空白符，例如：<strong>\n</strong>, <strong>\r</strong>, <strong>\t</strong>, <strong>‘ ‘</strong>)。</p><pre class=" language-python"><code class="language-python">str <span class="token operator">=</span> <span class="token string">'123@163.com'</span><span class="token keyword">print</span><span class="token punctuation">(</span>str<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'132'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#@163.com</span>str <span class="token operator">=</span> <span class="token string">'123@163.com'</span><span class="token keyword">print</span><span class="token punctuation">(</span>str<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'23'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#123@163.com</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习</title>
      <link href="pytorch-xue-xi/"/>
      <url>pytorch-xue-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><p>类似菜鸟教程：<a href="https://www.bootwiki.com/pytorch/pytorch-tutorial.html">https://www.bootwiki.com/pytorch/pytorch-tutorial.html</a></p><p>类似例程：<a href="https://github.com/yunjey/pytorch-tutorial">https://github.com/yunjey/pytorch-tutorial</a></p><p>Docs：<a href="https://github.com/fendouai/PyTorchDocs">https://github.com/fendouai/PyTorchDocs</a></p><p>handbook：<a href="https://github.com/zergtant/pytorch-handbook">https://github.com/zergtant/pytorch-handbook</a></p><p>pytorch API:<a href="https://pytorch.org/docs/stable/tensors.html?highlight=torch%20size#torch.Tensor.size">https://pytorch.org/docs/stable/tensors.html?highlight=torch%20size#torch.Tensor.size</a></p><p>torch运用就和np一样</p><p><strong>torch.tensor</strong></p><p>不是基本数据类型如int，float，string等，而是引用数据类型(JAVA中的概念：<a href="https://www.cnblogs.com/maskwolf/p/9972982.html)%EF%BC%8C%E6%98%AF%E5%9C%A8%E7%B1%BB%E4%B8%AD%E5%B0%81%E8%A3%85%E5%A5%BD%E7%9A%84%E3%80%82%E6%89%80%E4%BB%A5%E8%82%AF%E5%AE%9A%E7%9B%B8%E5%BA%94%E6%93%8D%E4%BD%9C%E6%AF%94%E5%A6%82%E8%BF%90%E7%AE%97%E7%AC%A6%E7%AD%89%E4%BA%BA%E5%AE%B6%E5%B7%B2%E7%BB%8F%E7%BB%99%E4%BD%A0%E9%87%8D%E8%BD%BD%E4%BA%86%EF%BC%8C%E6%89%80%E4%BB%A5%E4%B8%8D%E7%94%A8%E6%83%B3%E7%9A%84%E5%A4%AA%E5%A4%9A">https://www.cnblogs.com/maskwolf/p/9972982.html)，是在类中封装好的。所以肯定相应操作比如运算符等人家已经给你重载了，所以不用想的太多</a></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>numpy、pandas、matplotlib学习</title>
      <link href="numpy-he-pandas-xue-xi/"/>
      <url>numpy-he-pandas-xue-xi/</url>
      
        <content type="html"><![CDATA[<blockquote><p>jupyter notebook使用：<a href="https://zhuanlan.zhihu.com/p/32320214">https://zhuanlan.zhihu.com/p/32320214</a></p></blockquote><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><p>菜鸟教程：<a href="https://www.runoob.com/numpy/numpy-ndarray-object.html">https://www.runoob.com/numpy/numpy-ndarray-object.html</a></p><p>np.std()求标准差</p><p>Python<code>list</code>只能与整数相乘，在这种情况下，将<code>list</code>重复的元素：</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span></code></pre><p>如果要进行矢量运算，请<code>numpy.ndarray</code>改用：</p><pre class=" language-py"><code class="language-py">>>> import numpy as np>>> ar = np.array([1,2,3])>>> ar * 3array([3, 6, 9])</code></pre><p>numpy广播机制：<a href="https://zhuanlan.zhihu.com/p/60365398">https://zhuanlan.zhihu.com/p/60365398</a></p><p>np.linspace()和np.arrange()一个是样本数量，一个步长</p><h2 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h2><p>教程：<a href="https://www.yiibai.com/pandas/python_pandas_environment_setup.html">https://www.yiibai.com/pandas/python_pandas_environment_setup.html</a></p><p>API:<a href="https://pandas.pydata.org/pandas-docs/stable/reference/index.html">https://pandas.pydata.org/pandas-docs/stable/reference/index.html</a></p><p>将dataframe一行转化为int，astype</p><pre><code>top, right, bottom, left = row[0:].astype(int)</code></pre><p>获取dataframe的行数和列数</p><pre class=" language-python"><code class="language-python">df<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">//</span>行数df<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">//</span>列数</code></pre><h2 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><p>易百教程：<a href="https://www.yiibai.com/matplotlib">https://www.yiibai.com/matplotlib</a></p><p>API：<a href="https://matplotlib.org/3.3.2/api/index.html">https://matplotlib.org/3.3.2/api/index.html</a></p><p>假如目前只有一个figure1，你再绘图是在它上面不断覆盖的</p><p>分为plt绘图与axes绘图两种方式</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> numpy </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leetcode-tree</title>
      <link href="leetcode-tree/"/>
      <url>leetcode-tree/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> oj </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>托福笔记</title>
      <link href="tuo-fu-bi-ji/"/>
      <url>tuo-fu-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="曲根词汇"><a href="#曲根词汇" class="headerlink" title="曲根词汇"></a>曲根词汇</h2><h4 id="阅读记忆"><a href="#阅读记忆" class="headerlink" title="阅读记忆"></a>阅读记忆</h4><p>经济学人 时代 卫报</p><p>生词圈出，反复研读句子。勾画词组，了解替换，熟词辟意。</p><h4 id="词根词缀"><a href="#词根词缀" class="headerlink" title="词根词缀"></a>词根词缀</h4><p>prefix </p><ol><li>肯定，否定</li><li>方向</li><li>数字</li></ol><p>suffix</p><ol><li>词性</li></ol><p>root-根的逆推/想到熟词</p><ol><li>意义</li></ol><h4 id="词源-Etymology"><a href="#词源-Etymology" class="headerlink" title="词源 Etymology"></a>词源 Etymology</h4><p><strong>看读音，看拼写，看意思</strong></p><p>元音和元音字母组合之间可以替换：<strong>a,e,i,o,u,y</strong></p><p>辅音之间：<strong>p\b,t\d,k\g\c\qu\x,f\v,s\x\z\th</strong></p><p>形近字母的互换：<strong>u/v/w(特征是去掉元音),m/n（m/n可以省略）</strong></p><p>字母<strong>g、h</strong>的脱落（不发音）</p><p>造新词往往在<strong>单词结尾加轻辅音</strong></p><p>固定转换：s/t/d， p/b/ph/f/v        amorphous：form的倒写 </p><h4 id="字母组合（单音节，无词根词缀，-大体意思）"><a href="#字母组合（单音节，无词根词缀，-大体意思）" class="headerlink" title="字母组合（单音节，无词根词缀， 大体意思）"></a>字母组合（单音节，无词根词缀， 大体意思）</h4><p>sp表示发出，散开，产生</p><p>scr、cr多和手上的动作有关（注意：s在造词的时候无意义，只起到加强语气的作用）</p><p>词根词源字典：<a href="http://www.etymon.cn/index.html">http://www.etymon.cn/index.html</a></p><h4 id="联想法记单词"><a href="#联想法记单词" class="headerlink" title="联想法记单词"></a>联想法记单词</h4><p>单音节词汇 —-形近词  终点记不一样的地方</p><p>多音节词汇 —拆词，拆成认识的  词根词缀   拼音   熟词  与熟词形近的部分 等</p><p>​    </p><p>im/in: 1 into 2 not</p><p>vis: to see</p><p>it: to go</p><p>fact: to make</p><p>dis:1 not 2 apart</p><p>re:1 again 2 back</p><p>aneous:整体的形容词后缀</p><p>ade:名词后缀</p><p>er：n或v后缀，…的人</p><p>le:如果是动词，那么le就是动词后缀，往往表示动作的反复行为</p><p>ate:动词后缀</p><p>uous/ious/ous：形容词后缀</p><p>ish：形容词后缀，像$\cdots$一样的</p><p><strong>词根arch,archy= government,to rule统治</strong></p><p> ——词根arch 来自希腊语的arkhos，一般构成名词，亦可以当词根讲 意为government,to rule。arch 还有chief,first,old的含义。它们属于一对同源异形根，在派生词中，arch 常指统治的人物，作 ruler 统治者讲；而 archy 常指统治这一行为、方式，作rule 管理/管辖/统治或 government 政体讲。同义词根有来自希腊语的cracy/crat 和来自拉丁语的reg。</p><p>acc/app/ass/att，a+辅音双写表动作的加强</p><p>an/a：not</p><p><strong>后缀-ence,-ency的含义、词源和例词</strong></p><p>汉：来源于拉丁语及法语的名词后缀-ence(-ency)的用法与<a href="http://www.etymon.cn/yingyucizhui/yingyuhouzhui/205.html">-ance</a>(-ancy)基本相同。它们加在动词或动词词根后，意为the act or fact of ～ing或者the quality or condition of ～ing,即表示行为或该行为的性质状态等。这些名词往往有与之对应的以-ent结尾的形容词。</p><p> -ence,-ency与形容词后缀-ent相对应（如 difference-different；urgency-urgent），表示性质、状态、行为，后缀-ence和-ency义同，有些英语单词具有-ence和-ency两种形式（如 innocence = innocency ; persistency = persistence）</p><p>bene：词根 good male：词根evil</p><p>dict: to say</p><p>sion/dion: 名词后缀</p><p>vol:will 意愿</p>]]></content>
      
      
      <categories>
          
          <category> 英语 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tofel </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>颜色恒常性之Bayesiancolorconstancy</title>
      <link href="yan-se-heng-chang-xing-zhi-bayesiandecisiontheory/"/>
      <url>yan-se-heng-chang-xing-zhi-bayesiandecisiontheory/</url>
      
        <content type="html"><![CDATA[<h2 id="论文思路"><a href="#论文思路" class="headerlink" title="论文思路"></a>论文思路</h2><p>论文：&lt;&lt;Bayesian color constancy &gt;&gt;</p><h3 id="Title-amp-amp-Abstract"><a href="#Title-amp-amp-Abstract" class="headerlink" title="Title&amp;&amp;Abstract"></a>Title&amp;&amp;Abstract</h3><p>MSE:</p><p><a href="https://blog.csdn.net/qq_36512295/article/details/86526799">https://blog.csdn.net/qq_36512295/article/details/86526799</a></p><p>MMSE:</p><p><a href="https://blog.csdn.net/tanghonghanhaoli/article/details/82751690?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522160395601819724842903308%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=160395601819724842903308&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v28-28-82751690.first_rank_ecpm_v3_pc_rank_v2&amp;utm_term=MMSE&amp;spm=1018.2118.3001.4187">https://blog.csdn.net/tanghonghanhaoli/article/details/82751690?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522160395601819724842903308%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=160395601819724842903308&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v28-28-82751690.first_rank_ecpm_v3_pc_rank_v2&amp;utm_term=MMSE&amp;spm=1018.2118.3001.4187</a></p><blockquote><p>the Maximum Local Mass Estimate</p></blockquote><p><strong>什么是局部最大质量估计？</strong></p><h3 id="Figure"><a href="#Figure" class="headerlink" title="Figure"></a>Figure</h3><p><strong>Figure1</strong></p><blockquote><p>We assume that each surface is <strong>flat and matte</strong>, so that it may be characterized by a single spectral reflectance function</p></blockquote><p><strong>为什么要flat and matte?</strong></p><p>平坦是保证处处一致，无光泽不光滑是保证是漫反射吧应该？</p><blockquote><p>The spectral power distri- bution of the light reaching the observer from each surface is given as the <strong>wavelength-by-wavelength product</strong> of the illuminant spectral power distribution and the surface reflectance function.</p></blockquote><p><strong>什么是wavelength-by-wavelength product?</strong></p><p>二者直接相乘</p><p><strong>Figure2</strong></p><p>Fig2（a）:</p><p>对于简单的乘积例子，给定高斯噪声时，后验分布的图像，最优解在岭处</p><p>Fig2（b）：</p><p>横截面表明，即使在岭处都有最大的固定值，一些局部区域也会含有不同的概率质量</p><hr><p><strong>什么是parametre vector？参数是什么意思？</strong></p><p>参数，也叫参变量，是一个变量。我们在研究当前问题的时候，关心某几个变量的变化以及它们之间的相互关系，其中有一个或一些叫自变量，另一个或另一些叫因变量。如果我们引入一个或一些另外的变量来描述自变量与因变量的变化，引入的变量本来并不是当前问题必须研究的变量，我们把这样的变量叫做参变量或参数。英文名：Parameter。</p><p>这里的参数应该是指分类x，data是数据指y</p><p><strong>什么是rendering equation？</strong></p><p><a href="https://zhuanlan.zhihu.com/p/52497510">https://zhuanlan.zhihu.com/p/52497510</a></p><p><strong>什么是Gaussian observation noise？高斯噪声？</strong></p><p>高斯噪声百度百科：<a href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0/8587563?fr=aladdin">https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0/8587563?fr=aladdin</a></p><p>为什么深度学习去噪都采用高斯白噪声？<a href="https://www.zhihu.com/question/67938028">https://www.zhihu.com/question/67938028</a></p><p>高斯白噪声解释：<a href="https://blog.csdn.net/szlcw1/article/details/41758711">https://blog.csdn.net/szlcw1/article/details/41758711</a></p><p><strong>Figure3</strong></p><hr><p><strong>delta loss function损失函数？</strong></p><p>常见损失函数：<a href="https://blog.csdn.net/perfect1t/article/details/88199179">https://blog.csdn.net/perfect1t/article/details/88199179</a></p><p>应该就是指单峰函数，0-1函数$\delta(\widetilde{x}-x)=0\quad if(\widetilde{x}=x)$ 相同的是预判正确的，所以是没有损失的</p><p><strong>期望损失？</strong></p><p><a href="https://blog.csdn.net/hx14301009/article/details/79870851">https://blog.csdn.net/hx14301009/article/details/79870851</a></p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><h4 id="A-Why-Color-Constancy-is-Difficult"><a href="#A-Why-Color-Constancy-is-Difficult" class="headerlink" title="A. Why Color Constancy is Difficult"></a>A. Why Color Constancy is Difficult</h4><p>1.Problem Statement</p><blockquote><p>The entries of sj specify the fraction of incident light reflected in Nl evenly spaced wavelength bands throughout the visible spectrum</p></blockquote><p><strong>是不是错了，应该是reflected in</strong> $N_j$<strong>?这句话怎么理解?</strong></p><p>应该意思是$N_l$个均匀排列波长带</p><p>2.Why It Is Difficult</p><blockquote><p>It is underdetermined and it is nonlinear.</p></blockquote><p><strong>什么是欠定的？</strong></p><p><a href="http://blog.sina.com.cn/s/blog_531bb7630100xx6c.html">http://blog.sina.com.cn/s/blog_531bb7630100xx6c.html</a></p><blockquote><p>If we have data from N image locations (say, 10) and assume one illuminant, then we have NNr measurements (e.g., 10 x 3 = 30) available to estimate Nl(N + 1) scene parameters [e.g., 31 x (10 + 1) = 341].</p></blockquote><p><strong>这句话怎么理解？</strong></p><blockquote><p>To address the underdeterminancy of color constancy, previous investigators have described spectral functions by using low-dimensional linear models</p></blockquote><p>什么是低维线性模型？</p><p><a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1604305021&amp;ver=2681&amp;signature=FecbuKdwyqukrDBQO*pJ3q2jZFxLcCWxabeUx7eeSsOp9MNNUxijWNnlaNGRWguX2sl69suc3xXZInrRwvy-CsE1AVD*Vr3NvyjihI-8QmMzO04JeBJpKBXi75iy89*z&amp;new=1">https://mp.weixin.qq.com/s?src=11&amp;timestamp=1604305021&amp;ver=2681&amp;signature=FecbuKdwyqukrDBQO<em>pJ3q2jZFxLcCWxabeUx7eeSsOp9MNNUxijWNnlaNGRWguX2sl69suc3xXZInrRwvy-CsE1AVD</em>Vr3NvyjihI-8QmMzO04JeBJpKBXi75iy89*z&amp;new=1</a></p><blockquote><p>The columns of $B_e$ are the basis functions of the linear model, since the matrix product $B_ew_e$ expresses a weighted sum of these columns.</p></blockquote><p><strong>什么是基函数？</strong></p><p><a href="https://www.jianshu.com/p/5cc427f0df33">https://www.jianshu.com/p/5cc427f0df33</a></p><blockquote><p>If we assume that a population of spectra lie within an $N_m$-dimensional linear model, then we can parameterize the spectra by specifying the model weights.</p></blockquote><p><strong>这句话如何理解？</strong></p>]]></content>
      
      
      <categories>
          
          <category> Color Constancy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CC/AWB </tag>
            
            <tag> Bayes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>codeforces-1</title>
      <link href="codeforces-1/"/>
      <url>codeforces-1/</url>
      
        <content type="html"><![CDATA[<h2 id="1A-Theatre-Square-math"><a href="#1A-Theatre-Square-math" class="headerlink" title="1A Theatre Square-math"></a>1A Theatre Square-math</h2><blockquote><p>#include&lt;bits/stdc++.h&gt;</p><p>using namespace std</p><p>注意查看$1\leq n,m,a\leq 10^9$,所以可能数超大，使用<strong>long long</strong>定义</p><p>向上取整<strong>ceil()</strong>,向下取整<strong>floor()</strong>,四舍五入到最近整数<strong>round()</strong>,注意返回值是<strong>浮点数</strong>！</p><p>c++API：<a href="https://devdocs.io/cpp/">https://devdocs.io/cpp/</a></p></blockquote><pre class=" language-c++"><code class="language-c++">#include<bits/stdc++.h>int main(){    long long int n,m,a;    scanf("%lld %lld %lld",&n,&m,&a);    long long int rows,cols;    if((n%a)==0)        rows=n/a;    else         rows=n/a+1;    if(m%a==0)        cols=m/a;    else         cols=m/a+1;        printf("%lld",rows*cols);} </code></pre><h2 id="71A-Way-Too-Long-Words-strings"><a href="#71A-Way-Too-Long-Words-strings" class="headerlink" title="71A Way Too Long Words-strings"></a>71A Way Too Long Words-strings</h2><blockquote><p><strong>c++: string  建议是在程序中能使用C++字符串就使用，除非万不得已不选用c_string。</strong></p><p><a href="https://www.cnblogs.com/c1299401227/p/5370685.html">https://www.cnblogs.com/c1299401227/p/5370685.html</a></p><p><a href="https://blog.csdn.net/qq_42659468/article/details/90381985">https://blog.csdn.net/qq_42659468/article/details/90381985</a></p><p><a href="https://blog.csdn.net/liitdar/article/details/80498634">https://blog.csdn.net/liitdar/article/details/80498634</a></p><p><strong>重定向：</strong></p><p>//freopen(“in.txt”,”r”,stdin);</p><p><strong>输入输出：</strong></p><p><img src="/codeforces-1/image-20201030223138234.png" alt="题型"></p><p>对于这种类型的题，可以输入一个输出一个，用如下方式：</p><p>while(n–){ }</p><p><strong>c语言字符串:</strong></p><p>char word[nmax];  scanf(“%s”,word); strlen()</p><p>必须要指明nmax，你就算是定义数字数组也要指明nmax呀，否则就得动态分配。</p><p><a href="https://www.cnblogs.com/tongye/p/10688941.html">https://www.cnblogs.com/tongye/p/10688941.html</a></p></blockquote><pre class=" language-c++"><code class="language-c++">#include<bits/stdc++.h>using namespace std;int main(){    int n;    cin>>n;    string s;    for(int i=0;i<n;i++){        cin>>s;        if(s.size()>10)            cout<<s[0]<<s.size()-2<<s[s.size()-1]<<endl;//注意换行        else            cout<<s<<endl;    }    return 0;}</code></pre><h2 id="118-AStringTask"><a href="#118-AStringTask" class="headerlink" title="118 AStringTask"></a>118 AStringTask</h2><blockquote><p>字符串大小写转换：没有直接的转换函数，可以直接利用ascii码字符加减</p><p>对字符串变换，可以新设一个字符串，也可逐字符输出，是个黑盒子，它不管你怎么操作的，结果对了就行</p></blockquote><pre class=" language-c++"><code class="language-c++">if (str[i]=='a'||str[i]=='e'||str[i]=='i'||str[i]=='o'||str[i]=='u'||str[i]=='y'){  str[i]=-1; //这里做一个假删除}if (str[i]!=-1){  printf(".");  printf("%c",str[i]);}</code></pre><pre class=" language-c++"><code class="language-c++">#include<bits/stdc++.h>using namespace std;int main(){    string s;    cin>>s;    string ans="";    for(int i=0;i<s.size();i++){        if(s[i]>='A'&&s[i]<='Z')            s[i]=s[i]-'A'+'a';        if(s[i]!='a'&&s[i]!='o'&&s[i]!='y'&&s[i]!='e'&&s[i]!='u'&&s[i]!='i'){            ans=ans+'.'+s[i];         }    }    cout<<ans;    return 0;}</code></pre><h2 id="78A-Football"><a href="#78A-Football" class="headerlink" title="78A Football"></a>78A Football</h2><blockquote><p>连续子串等连续问题，可以设一个变量或数组，每一次修改都在前一位的基础上修改</p></blockquote><pre class=" language-c++"><code class="language-c++">#include<bits/stdc++.h>using namespace std;int main(){    string s;    cin>>s;    int a=0,b=0,flag=0;    for(int i=0;i<s.size();i++){        if(s[i]=='0'){            a++;            b=0;        }        else{            a=0;            b++;        }        if(a==7||b==7){            flag=1;            cout<<"YES";            break;         }    }    if(flag==0)        cout<<"NO";    return 0;}</code></pre><h2 id="230ADragons"><a href="#230ADragons" class="headerlink" title="230ADragons"></a>230ADragons</h2><blockquote><p>c++中sort函数使用方法：<a href="https://www.cnblogs.com/junbaobei/p/10776066.html">https://www.cnblogs.com/junbaobei/p/10776066.html</a></p><p>迭代器：<a href="https://blog.csdn.net/qq_34777600/article/details/80427463">https://blog.csdn.net/qq_34777600/article/details/80427463</a></p><p>sort小总结：<a href="https://blog.csdn.net/yulijuanxmu/article/details/80148417">https://blog.csdn.net/yulijuanxmu/article/details/80148417</a></p></blockquote><pre class=" language-c++"><code class="language-c++">#include<bits/stdc++.h>using namespace std;//typedef struct node{//这种使用typedef 也可以不用 不一定非要用链表 //    int x;//    int y;//}Dragon; struct Dragon{    int x;    int y;};//注意句号 bool cmp(Dragon a,Dragon b){    return a.x<b.x;//前面的小于后面的，排序也一致 }int main(){    int s,n;    cin>>s>>n;    Dragon dragons[n];    for(int i=0;i<n;i++){        cin>>dragons[i].x>>dragons[i].y;    }    sort(dragons,dragons+n,cmp);    for(int i=0;i<n;i++){        if(s>dragons[i].x)            s+=dragons[i].y;        else{            cout<<"NO";//得到了想要的可以直接return             return 0;            }    }    cout<<"YES";    return 0;}</code></pre><h2 id="455A-Boredom"><a href="#455A-Boredom" class="headerlink" title="455A Boredom"></a>455A Boredom</h2><p>**动态规划：从新手到专家:**<a href="http://hawstein.com/2013/03/26/dp-novice-to-advanced/">http://hawstein.com/2013/03/26/dp-novice-to-advanced/</a></p><p><strong>子串:串中任意个连续的字符组成的子序列称为该串的子串.</strong></p><p><strong>子序列:子数列，又称子序列，在数学中，某个序列的子序列是从最初序列通过,去除某些元素但不破坏余下元素的相对位置（在前或在后）而形成的新序列。</strong></p>]]></content>
      
      
      <categories>
          
          <category> oj </category>
          
      </categories>
      
      
        <tags>
            
            <tag> codeforces </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>组会总结</title>
      <link href="zu-hui-zong-jie/"/>
      <url>zu-hui-zong-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="10-20"><a href="#10-20" class="headerlink" title="10.20"></a>10.20</h2><ol><li>ACCV 大概在六七月份</li><li>为什么定这几级，理论依据是什么？现有的分级标准，为什么这么分？理论依据？出于什么考量？</li><li>写论文博客时，要分两个过程，自己读主要写每个细节，按照论文的流程走下来；和别人讲、真正理解是要按自己的思路把整个流程理一遍</li><li><img src="/zu-hui-zong-jie/image-20201021103706939.png" alt="IJCAI"></li><li><img src="/zu-hui-zong-jie/image-20201021103921695.png" alt="ICCV"></li></ol><h2 id="10-30"><a href="#10-30" class="headerlink" title="10.30"></a>10.30</h2><ol><li>DCT、GAN、自监督</li><li>学习宇翔学长如何讲</li><li>时间和效率都要保证 太堕落了</li><li>下次组会前要把三篇贝叶斯看完加代码整完</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>conda使用</title>
      <link href="conda-shi-yong/"/>
      <url>conda-shi-yong/</url>
      
        <content type="html"><![CDATA[<p>pip安装包应该是安装到了Lib/site-packages</p><p>菜鸟教程pip使用介绍：<a href="https://www.runoob.com/w3cnote/python-pip-install-usage.html">https://www.runoob.com/w3cnote/python-pip-install-usage.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件使用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人随想</title>
      <link href="ge-ren-sui-xiang/"/>
      <url>ge-ren-sui-xiang/</url>
      
        <content type="html"><![CDATA[<ol><li>早晨和下午的大块时间要利用好，攻坚论文或代码，晚上可以适当娱乐或者做一些其他的小事情，做事情不是给别人看的，而是你真的做出了成绩</li><li>适当的休息，不然眼睛太累了。</li><li>有时候商场打折的衣服比网上的还便宜还好！</li><li>能打的代码批量处理千万不要手动标累死你</li><li>关于博客，还弄的就是cdn加速、图床和说说界面</li></ol>]]></content>
      
      
      <categories>
          
          <category> 胡言乱语 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 胡言乱语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>奇奇怪怪不成体系问题合集</title>
      <link href="qi-qi-guai-guai-bu-cheng-ti-xi-wen-ti-he-ji/"/>
      <url>qi-qi-guai-guai-bu-cheng-ti-xi-wen-ti-he-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="HP打印机状态需要注意、打印显示用户干预如何处理？"><a href="#HP打印机状态需要注意、打印显示用户干预如何处理？" class="headerlink" title="HP打印机状态需要注意、打印显示用户干预如何处理？"></a>HP打印机状态需要注意、打印显示用户干预如何处理？</h2><p>和打印机连接在<strong>同一Wifi并已经添加了打印机</strong>的情况下，<strong>右键打印机</strong>-&gt;<strong>属性</strong>-&gt;<strong>Web服务</strong>，获得<strong>打印机IP</strong>，然后<strong>右键打印机</strong>-&gt;<strong>打印机属性</strong>-&gt;<strong>端口</strong>-&gt;<strong>添加端口</strong>-&gt;<strong>Standard TCP/IP Port</strong>-&gt;<strong>输入你的打印机的IP</strong>-&gt;<strong>填写随便一个端口名</strong>-&gt;<strong>应用</strong>-&gt;<strong>问题解决</strong>！</p><h2 id="文件扩展名？什么是-mat文件？"><a href="#文件扩展名？什么是-mat文件？" class="headerlink" title="文件扩展名？什么是.mat文件？"></a>文件扩展名？什么是.mat文件？</h2><p>文件扩展名查询：<a href="https://www.reviversoft.com/zh-cn/file-extensions/mat">https://www.reviversoft.com/zh-cn/file-extensions/mat</a></p><h2 id="Chrome实时字幕打开？"><a href="#Chrome实时字幕打开？" class="headerlink" title="Chrome实时字幕打开？"></a>Chrome实时字幕打开？</h2><p>首先，将Chrome更新到Canary 84.0.4136.1或更高版本，接着在地址栏中输入“Chrome://flags”，进入到Chrome的实验功能界面。</p><p>搜索“Live Captions”，将这个实时字幕的选项打开。</p><p>重启Chrome，进入到设置界面。在“高级”中找到“无障碍”，就可以看到实时字幕功能了，开启即可。</p>]]></content>
      
      
      <categories>
          
          <category> 奇奇怪怪 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 奇怪 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>肤色分级与系统</title>
      <link href="fu-se-fen-ji-yu-xi-tong/"/>
      <url>fu-se-fen-ji-yu-xi-tong/</url>
      
        <content type="html"><![CDATA[<h2 id="论文阅读-lt-lt-Brief-overview-of-PANTONE-SkinTone-Guide-chart-in-CIEL-a-b-color-space-gt-gt"><a href="#论文阅读-lt-lt-Brief-overview-of-PANTONE-SkinTone-Guide-chart-in-CIEL-a-b-color-space-gt-gt" class="headerlink" title="论文阅读-<<Brief overview of PANTONE SkinTone Guide chart in CIEL*a*b* color space>>"></a>论文阅读-&lt;&lt;Brief overview of PANTONE SkinTone Guide chart in CIEL*a*b* color space&gt;&gt;</h2><h3 id="Title-amp-Keywords-amp-Abstract-amp-Conclusion"><a href="#Title-amp-Keywords-amp-Abstract-amp-Conclusion" class="headerlink" title="Title&amp;Keywords&amp;Abstract&amp;Conclusion"></a>Title&amp;Keywords&amp;Abstract&amp;Conclusion</h3><h4 id="CIEL-a-b-color-space"><a href="#CIEL-a-b-color-space" class="headerlink" title="CIEL*a*b* color space?"></a>CIEL*a*b* color space?</h4><p><strong>颜色开发培训讲义</strong>：<a href="https://www.zhihu.com/column/cxqingzong-color">https://www.zhihu.com/column/cxqingzong-color</a>     <strong>这篇不能更赞</strong></p><p><strong>可见光谱:</strong></p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201014213348777.png" alt="可见光谱"></p><p>我们所说的<strong>颜色主要分两种</strong>：</p><blockquote><p><strong>光源色（light source color）</strong>：来自发光体的颜色。如太阳，灯泡，led灯，等等。</p><p><strong>表面色（surface color</strong>）：不是来自发光体的物体色。物体本身不发光，但能看到物体的颜色，是因为这些物体能对来自于其他发光体的光的选择性的吸收和反射。</p></blockquote><p>颜色也可以简单分为两大类：</p><blockquote><p><strong>非彩色</strong>：黑白灰</p><p><strong>彩色</strong>：红黄蓝绿等</p></blockquote><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201014210822647.png" alt="彩色与非彩色"></p><p><strong>颜色感知的三要素，光源，物体和观察者，缺一不可，缺少一个要素，我们看不到颜色，或者其中一个要素发生改变，我们看到的颜色都会不一样。</strong></p><p><strong>1光源</strong></p><p><strong>不同光源性质是不一样的</strong>，有些光源会亮一点白一点，如太阳，或者就是太阳光，一天内不同时间段的太阳光也会有很大差异，导致在这些不同的光源下看相同一个颜色都会有很大差异.</p><p>所以我们在<strong>颜色开发或者颜色沟通交流的时候，会指定一个标准光源</strong>，这样能确保我们双方看颜色条件的一致性。我们比对颜色使用的光源都是有标准规定的光源。通常在下图所示的对色灯箱里看颜色。灯箱里面装有不同的常用光源。</p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201014215437189.png" alt="对色灯塔及常见光源" style="zoom: 67%;"><blockquote><p><strong>Light sources：发光体（照明体）</strong>。泛指能发出光（可见光）的物体，如太阳，蜡烛，灯泡等。但是有些发光体发出的光是变化的不稳定的。例如太阳光，就算在同一天光照辐射都是不一样的，是变化的，更何况在不同的天气，不同的季节。所以很难用这些不稳定的光源来进行对颜色的描述和交流。</p><p><strong>lluminants：光源</strong>。是一个可以定量描述的发光体。是国际照明委员会 CIE（Commission Internationale de L’Eclairage）为了对颜色的评估和计算而定义了不同类型的，能用数学表（相对能量和波长)表示的标准光源。</p></blockquote><p><strong>色温Color temperature是照明光学中用于定义光源颜色的一个物理量。光源的色温是以光源发光时所显现的颜色与一个绝对黑体被高温燃烧时所显现的颜色相一致时的燃烧温度来定义的，它的单位是绝对温度Kelvin开尔文【K】。是为了量化光源色彩的一个物理量</strong></p><p>开尔文与摄氏度的转换关系如下：</p><p><strong>K(开尔文）=273.15+T(摄氏度）</strong></p><p>K值越高，显现的颜色就愈趋向于白蓝色；K值越低，显现的颜色就愈趋向于黄红色。</p><p>开尔文认为，假定纯黑体，能够将落在其上的所有热量吸收，而没有损失，同时又能够将热量生成的能量全部以“光”的形式释放出来的话，它产生辐射最大强度的波长随温度变化而变化。</p><p><strong>显色指数color rendering index (CRI)</strong> :<strong>与标准的参考光源相比较，一个光源对物体颜色外貌所产生的效果</strong>。换句话说，是<strong>一个光源与标准光源（例如日光）相比较下在颜色辨认方面的一种测量方式</strong>。CRI是一种得到普遍认可的度量标准，也是目前评价与报告<strong>光源显色性</strong>的惟一途径。</p><p><strong>Ra</strong> <strong>=</strong> <strong>物体在某一光源照射下所显现的颜色 ÷ 物体本身所具有的颜色</strong>。</p><p>Ra表示某光源的显色指数。Ra愈接近100%，<strong>表明在该光源照射下，物体所显现的颜色与物体本身所具有的颜色的差异就愈小</strong>。</p><p><strong>标准光源</strong>的光谱要求如下：</p><p>（1）光源的<strong>色温必须是5000K-6500K</strong>，在这种光源色温下观察颜色的效果基本类似于中国大部分地区上午8点至10点，下午3点至5点的自然光下的观察效果。</p><p>（2）光源的<strong>显色指数Ra&gt;90</strong></p><p>光源的性质，可以通过<strong>光谱功率分布曲线（SPD）</strong>来描述。不同的光源有着不同的光谱功率分布曲线。光谱功率分布（SPD）的意思就是光源发出可见光的不同光谱波长（400nm~700nm）的功率是不同的。功率可以理解成强度的大小。</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015094547985.png" alt="常用光源的光谱功率分布曲线"></p><p><strong>2物体</strong></p><blockquote><p><strong>物体关于颜色的性质是对不同波长的电磁波的选择性吸收</strong>，所以我们用<strong>光谱反射率曲线</strong>来表达物体的这种性质。<strong>红色绿色蓝色</strong>的光谱反射率曲线的<strong>最大特征</strong>是，它<strong>有明显的波峰</strong>。<strong>波峰所在的位置的电磁波波长代表着这个物体的颜色</strong>。</p><p>但是<strong>黑白灰</strong>就不一样。物体之所以能够呈现出<strong>白色</strong>，是因为这个物体对<strong>不同波长的电磁波几乎都不吸收</strong>，所以都被反射出来。<strong>黑色</strong>跟白色刚好相反，黑色物体<strong>几乎完全吸收所有波长的电磁波</strong>，所以从黑色的光谱反射率曲线来看，所有波长的光谱的反射率都很低很低。</p></blockquote><p><strong>3观察者人眼：</strong></p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015095247048.png" alt="人眼观察黄光" style="zoom:67%;"><p>类似人眼三种视锥细胞对不同波长的光的响应，研究人员也得到一个标准观察者的三刺激值（x，y，z），作为测色仪辨别颜色的视锥细胞。通过这三个参数xyz，来描述一个颜色，也就是后面将要介绍的<strong>CIE-XYZ颜色空间</strong>。</p><p><strong>CIE-XYZ颜色空间：</strong></p><p>我们将<strong>光源</strong>、<strong>物体</strong>和<strong>观察者</strong>这三要素的性质相乘，也就是光源的光谱功率分布曲线乘以物体的光谱反射率曲线乘以标准观察者，得到三个参数<strong>X，Y，Z</strong>（都是大写字母），不同的颜色，有着不同XYZ值。</p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015100147722.png" alt="CIEXYZ" style="zoom:80%;"><p>按照下图里的公式算出<strong>x</strong>（小写X），<strong>y</strong>（小写Y）。<strong>xyz值（小写）代表着XYZ（大写）的占比</strong>，这样三个参数缩减到两个参数，<strong>两个参数形成一个平面的二维颜色空间，也就是CIE-XYZ颜色空间</strong>。CIE XYZ颜色空间具有不均匀性。</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015100255681.png" alt="CIE-XYZ颜色空间"></p><p><strong>缺点：不容易对颜色差异的大小进行判定</strong>，<strong>无法非常直观的判定这个颜色</strong>就是我需要的颜色，不知道这个颜色跟我需要的颜色的差异的大小。</p><p>我们把<strong>人眼感觉不出的色彩差别量（变化范围）叫做颜色的宽容量</strong>。颜色的宽容量反映在<strong>CIExy色度图上即为两个色度点之间的距离</strong>。因为，每种颜色在色度图上是一个点，但<strong>对人的视感觉来说，当这种颜色的色度坐标位置变化很小时，人眼仍认为它是原来的颜色，感觉不出它的变化。</strong>所以，对视感觉效果来说，<strong>在这个变化的距离（或范围）以内的色彩差别量，在视觉效果上是等效的。</strong>对色彩复制和其它颜色工业部门来说这种位于人眼宽容量范围之内的色彩差别量是允许存在的。</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015220402922.png" alt="不同标准色度点的颜色宽容量"></p><p><strong>CIE-L*a*b*颜色空间：</strong></p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201016174528078.png" alt="介绍"></p><p>跟之前介绍的孟塞尔颜色体系的颜色空间是一样，是三维空间中立体的球形。空间中有三个维度，形成三个互相垂直的轴，分别是：</p><ul><li>L*轴：从上到下；<strong>表示明度</strong>，范围由0到100，表示颜色从深（黑）到浅（白）。</li><li>a*轴：从左到右；<strong>表示红绿</strong>，数值变化由正到负，表示颜色从红（正）到绿（负）。a值越大颜色越红，a值越小颜色越绿。</li><li>b*轴：从里到外。<strong>表示黄蓝</strong>，数值变化由正到负，表示颜色从黄（正）到蓝（负）。b值越大颜色越黄，b值越小颜色越蓝。</li><li><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015100941807.png" alt="CIE-L*a*b*"></li></ul><p><strong>两个颜色之间的差异大小</strong>。引入一个概念——<strong>色差△E</strong>。<strong>两个颜色的差异大小，就是这两个颜色的在颜色空间上两个点的距离</strong>。色差的计算公式如下：</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015100802146.png" alt="色差的计算公式"></p><p><strong>同色异谱：</strong></p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019221820491.png" alt="同色异谱"></p><blockquote><p>有时候我们看两个物体的颜色，在某种场景下，比如上图左边的两个物体在室外太阳光底线看起来颜色的一样的，但是一旦我们拿到室内，如上图右边，在荧光灯管底线发现，其实这两个物体的颜色是相差非常大的。这就是同色异谱现象，<strong>同色异谱也叫做条件对色</strong>，顾名思义，这两个颜色只有符合一定观察条件下颜色才能相等，实际上这两个颜色并非完全一样。</p></blockquote><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019222411178.png" alt="同色异谱"></p><blockquote><p><strong>同色异谱（条件等色）的根源在于两物体的光谱反射率曲线不同</strong>，也就是说有不同的颜色色粉配方。同色异谱中的<strong>“谱”指的就是光谱反射率曲线</strong>。如下图，就是上面两个颜色色卡的光谱反射率曲线，可以看到两者的差异是非常大的。也可以看到两个光谱反射率曲线的交叉点很多。</p><p>《颜色技术原理》中提到过史泰鲁斯 （stiles）和 维 泽 斯 基（ wyszecki）发现两个同色异谱的颜色的光谱反射曲线在可见光谱波段 （400~700nm） 内， 至少在三个不同波长上必须具有相同的反射率。也就是两者的光谱反射率曲线至少要有三个交叉点 。</p></blockquote><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019222914891.png" alt="不同的光谱反射率曲线"></p><p>常见颜色空间介绍：<a href="https://blog.csdn.net/JiangHui1211/article/details/84592774?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param">https://blog.csdn.net/JiangHui1211/article/details/84592774?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param</a></p><p><strong>RGB颜色空间</strong>:</p><p><strong>任意色光F</strong>都可以用RGB<strong>三种颜色不同分量的相加混合而成</strong>：**F=r[R]+g[G]+b[B]**。</p><p><strong>一般我们读取图片获得的三维矩阵是RGB空间</strong></p><p><strong>色度学规则</strong>：<br>　　(1)通过<strong>R,G,B这三种颜色能产生任何颜色</strong>，并且<strong>这三种颜色混合后产生的颜色是唯一</strong>的。<br>　　(2)如果<strong>两个颜色相等，这三个颜色分量再乘以或者除以相同的数，得到的颜色仍然相等</strong>。<br>　　(3)<strong>混合色的亮度等于每种颜色亮度的和</strong>。</p><p><strong>RGB颜色空间</strong>的<strong>均匀性非常差，且两种颜色之间的知觉差异色差不能表示为该颜色空间中两点间的距离</strong>，但是<strong>利用线性或非线性变换</strong>，则<strong>可以从RGB颜色空间推导出其他的颜色特征空间</strong>。</p><p><strong>CMYK模式：</strong></p><p>俗称<strong>四色打印模式</strong>，是最佳的打印模式。因为在实际应用中，青色、洋红色和黄色很难叠加形成真正的黑色，最多不过是褐色而已。因此才引入了K——黑色。黑色的作用是强化暗调，加深暗部色彩。</p><p><strong>HSV颜色空间：</strong></p><p>感觉和孟塞尔颜色体系很像。**HSV即色相(Hue)、饱和度(Saturation)、明度(Value)，又称HSB(B即Brightness)**。</p><p>RGB和CMYK<strong>面向硬件</strong>，可用于<strong>图片编码</strong>；HSV<strong>面向用户</strong>，可用于<strong>图片编辑软件</strong>。</p><p><strong>sRGB色彩空间：</strong></p><p>standard Red Green Blue，<strong>标准红绿蓝色彩空间</strong>是惠普与微软于1996年一起开发的用于<strong>显示器、打印机以及因特网的一种标准RGB</strong>色彩空间。这种标准得到了W3C、Exif、英特尔、Pantone、Corel以及其它许多业界厂商的支持。</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015222536629.png" alt="sRGB色域"></p><p>维基百科：<a href="https://zh.wikipedia.org/wiki/Lab%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%97%B4">https://zh.wikipedia.org/wiki/Lab%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%97%B4</a></p><p>在<strong>RGB</strong>或<strong>CMYK</strong>值与<strong>L*a*b*</strong> 之间没有转换的简单公式，因为<strong>RGB和CMYK色彩空间是设备依赖的</strong>。RGB或CMYK值<strong>首先必须被变换到特定绝对色彩空间中，比如sRGB或Adobe RGB</strong>。这种调整将是设备依赖的，但是<strong>变换的结果数据是设备无关的</strong>，允许把数据变换成<strong>CIE 1931色彩空间</strong>并接着变换成<strong>L*a*b*</strong>。</p><h4 id="Hue-Angle色相角"><a href="#Hue-Angle色相角" class="headerlink" title="Hue Angle色相角?"></a>Hue Angle色相角?</h4><blockquote><p>孟塞尔颜色体系：</p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201014214736980.png" alt="image-20201014214736980" style="zoom:50%;"><p><strong>1）色相/色调/Hue</strong>，对于色相我们比较熟悉的是这个色环，色环上不同位置代表不同色相。色相的排列顺序是按照可见光波长从低到高，逆时针分布。这是色相环的概念。把一周均分成五5种主色互相调和成五种中间色，相邻的两个位置之间再均分10份，共100份</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015221249004.png" alt="色相带"></p><p><strong>2）明度/Value/Lightness</strong>，很容易理解，就是一个颜色中含有白和黑的比例：白越多黑越少，这个颜色的明度就越高。</p><p><strong>3）色度chroma</strong>。是一个颜色里面含有这个色相的浓度。<strong>很多人容易把饱和度和明度的概念混淆。是因为他们不理解饱和度和明度在色彩空间中的位置。明度在色彩空间中的位置是从顶部到底部，明度从高到低。而饱和度在色彩空间中的位置是从里到外，饱和度从低到高。</strong></p></blockquote><h4 id="色度-色域？"><a href="#色度-色域？" class="headerlink" title="色度?色域？"></a>色度?色域？</h4><p>研究颜色测量的学科叫做<strong>色度学</strong>，色度学的任务就是用数量化来表征色觉特性。色度”中的“度”是度量的意思。 类似于长度，高度等等概念。度量长度或高度使用的工具是尺子，而度量颜色的工具就是<strong>颜色感知三要素</strong>。</p><p><strong>色域</strong>是对一种颜色进行编码的方法，也指一个技术系统能够产生的颜色的总合。在计算机图形处理中，色域是<strong>颜色的某个完全的子集</strong>。颜色子集最常见的应用是用来精确地代表一种给定的情况。例如一个给定的色彩空间或是某个输出装置的呈色范围。</p><h3 id="Figure"><a href="#Figure" class="headerlink" title="Figure"></a>Figure</h3><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019170452039.png" alt="Table1" style="zoom:50%;"><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019170512027.png" alt="Table2" style="zoom:50%;"><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019170533519.png" alt="Figure1" style="zoom:50%;"><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019170555412.png" alt="Figure2" style="zoom:50%;"><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019170613588.png" alt="Figure3" style="zoom:50%;"><blockquote><p>lightness and chroma:亮度和色度</p><p>yellow and red categories:Hue色相</p></blockquote><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019215839363.png" alt="观察者"></p><blockquote><p>用于色彩排列和分类的这种三维系统已经融入目前广泛使用的<strong>色彩空间模型、色差公式和色容差系统</strong>。</p></blockquote><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019223925779.png" alt="转换" style="zoom:67%;"><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019224245507.png" alt="从色彩到色彩测量" style="zoom:50%;"><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019224402876.png" alt="从色彩到色彩测量" style="zoom:50%;"><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><blockquote><p><strong>Applications</strong>:</p><ol><li>diagnosis and treatments of cutaneous disorders </li><li>matching our body color to get maxillofacial soft tissue prostheses</li><li>face detection and recognition</li><li>cosmetics</li></ol><p>CIEL*a*b* is a <strong>device-independent color space</strong> which we used in our study.</p></blockquote><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><blockquote><p>110 colors numbered from 1Y01 SP to 4R15 SP</p><p> the first number <strong>indicates the chroma, varies from 1 to 5</strong> which it is the highest</p><p> the rigid represents <strong>yellowness (Y)</strong> or <strong>redness (R) as hue</strong> and </p><p><strong>two last numbers show the lightness, varies from 1 to 15</strong> which it is the darkest. These samples are sorted in <strong>decreasing order</strong> of lightness (5).</p></blockquote><h2 id="小实验"><a href="#小实验" class="headerlink" title="小实验"></a>小实验</h2><blockquote><p>MATLAB Api：<a href="https://www.mathworks.com/help/">https://www.mathworks.com/help/</a></p></blockquote><pre class=" language-matlab"><code class="language-matlab"><span class="token comment" spellcheck="true">% shows example of illuminant estimation based on Grey-World, Shades of</span><span class="token comment" spellcheck="true">% Gray, max-RGB, and Grey-Edge algorithm</span><span class="token comment" spellcheck="true">%example images</span>input_im<span class="token operator">=</span><span class="token function">double</span><span class="token punctuation">(</span><span class="token function">imread</span><span class="token punctuation">(</span><span class="token string">'test_3.jpg'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">figure</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">imshow</span><span class="token punctuation">(</span><span class="token function">uint8</span><span class="token punctuation">(</span>input_im<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'input image'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">% %Grey-World</span><span class="token comment" spellcheck="true">% [wR,wG,wB,out]=general_cc(input_im,0,1,0);</span><span class="token comment" spellcheck="true">% figure(2);</span><span class="token comment" spellcheck="true">% imshow(uint8(out));</span><span class="token comment" spellcheck="true">% title(</span><span class="token string">'Grey-World'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">%max-RGB</span><span class="token comment" spellcheck="true">% [wR,wG,wB,out]=general_cc(input_im,0,-1,0);</span><span class="token comment" spellcheck="true">% figure(3);imshow(uint8(out));</span><span class="token comment" spellcheck="true">% title(</span><span class="token string">'max-RGB'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">% Shades of Grey</span>mink_norm<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">% any number between 1 and infinity</span><span class="token punctuation">[</span>wR<span class="token punctuation">,</span>wG<span class="token punctuation">,</span>wB<span class="token punctuation">,</span>out<span class="token punctuation">]</span><span class="token operator">=</span><span class="token function">general_cc</span><span class="token punctuation">(</span>input_im<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span>mink_norm<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">figure</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">imshow</span><span class="token punctuation">(</span><span class="token function">uint8</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">title</span><span class="token punctuation">(</span><span class="token string">'Shades of Grey'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">% Grey-Edge</span><span class="token comment" spellcheck="true">% mink_norm=5;    % any number between 1 and infinity</span><span class="token comment" spellcheck="true">% sigma=2;        % sigma </span><span class="token comment" spellcheck="true">% diff_order=1;   % differentiation order (1 or 2)</span><span class="token comment" spellcheck="true">% [wR,wG,wB,out]=general_cc(input_im,diff_order,mink_norm,sigma);</span><span class="token comment" spellcheck="true">% figure(5);imshow(uint8(out));</span><span class="token comment" spellcheck="true">% title(</span><span class="token string">'Grey-Edge'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">% 截取皮肤区域</span><span class="token comment" spellcheck="true">% out=out(375:480,185:290,:);</span><span class="token comment" spellcheck="true">% out=out(360:420,360:420,:);</span>out<span class="token operator">=</span><span class="token function">out</span><span class="token punctuation">(</span><span class="token number">165</span><span class="token operator">:</span><span class="token number">240</span><span class="token punctuation">,</span><span class="token number">230</span><span class="token operator">:</span><span class="token number">320</span><span class="token punctuation">,</span><span class="token operator">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">% 展示截取皮肤区域</span><span class="token function">figure</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">imshow</span><span class="token punctuation">(</span><span class="token function">uint8</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">% convert to lab</span>labI <span class="token operator">=</span> <span class="token function">rgb2lab</span><span class="token punctuation">(</span><span class="token function">uint8</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">%seperate l,a,b</span><span class="token comment" spellcheck="true">%matlab的下标从1开始</span>l <span class="token operator">=</span> <span class="token function">labI</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span><span class="token operator">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>a <span class="token operator">=</span> <span class="token function">labI</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span><span class="token operator">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>b <span class="token operator">=</span> <span class="token function">labI</span><span class="token punctuation">(</span><span class="token operator">:</span><span class="token punctuation">,</span><span class="token operator">:</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">% % 显示各维度直方图</span><span class="token comment" spellcheck="true">% figure(4);</span><span class="token comment" spellcheck="true">% hist(l);</span><span class="token comment" spellcheck="true">% figure(5);</span><span class="token comment" spellcheck="true">% hist(a);</span><span class="token comment" spellcheck="true">% figure(6);</span><span class="token comment" spellcheck="true">% hist(b);</span><span class="token comment" spellcheck="true">%网格曲面图</span><span class="token function">figure</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">meshc</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>l<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">subplot</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">meshz</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>l<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><img src="/fu-se-fen-ji-yu-xi-tong/result_0.png" alt="result_0" style="zoom: 50%;"><img src="/fu-se-fen-ji-yu-xi-tong/result_1.png" alt="result_1" style="zoom: 50%;"><p><img src="/fu-se-fen-ji-yu-xi-tong/result_3.png" alt="result_3" style="zoom: 67%;"><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019214729213.png" alt="image-20201019214729213"></p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019214825960.png" alt="三维图" style="zoom:80%;"><h2 id="接下来打算要做"><a href="#接下来打算要做" class="headerlink" title="接下来打算要做"></a>接下来打算要做</h2><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201019155029016.png" alt="计划流程图"></p><h2 id="Pantone-Skintone-Review"><a href="#Pantone-Skintone-Review" class="headerlink" title="Pantone Skintone Review"></a>Pantone Skintone Review</h2><p>彩通肤色指南[PANTONE SkinTone Guide]是根据科学测量各种人类皮肤类型中数干种实际肤色而建立。这个色库为再现实体肤色而配制，是人类肤色的完整视觉参考，适用于与肤色相关的任何市场。</p><p>首个匹配和再现逼真肤色的科学指南，适用于各个行业。1000多种人体皮肤测量值，收集于不同年龄和种族的参与者。为获得一致的样品精确度．采用几种高端X—Rite分光光度计和小巧的手持PANTONE CAPSURE分光光度计来测量皮肤样本。根据这些测量值，Pantone<br>建立了精确的皮肤色彩空间．并创建了彩通肤色色库(PANTONE SkinToneLibrary)．它确定了1 10种再现性最强的色彩。<br><strong>现有的主要问题是，这110种肤色是如何确定的？</strong></p><p><strong>这也是我们需要做的！</strong></p>]]></content>
      
      
      <categories>
          
          <category> 肤色分级 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 肤色分级 </tag>
            
            <tag> 颜色空间 </tag>
            
            <tag> MATLAB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献图书资源搜索与使用管理</title>
      <link href="wen-xian-tu-shu-zi-yuan-sou-suo-yu-shi-yong-guan-li/"/>
      <url>wen-xian-tu-shu-zi-yuan-sou-suo-yu-shi-yong-guan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="文献引用信息有误"><a href="#文献引用信息有误" class="headerlink" title="文献引用信息有误"></a>文献引用信息有误</h2><blockquote><p>进入Mendeley网站，搜索出错的文献，然后“+Add to library”</p></blockquote><img src="/wen-xian-tu-shu-zi-yuan-sou-suo-yu-shi-yong-guan-li/image-20201012160759194.png" alt="image-20201012160759194" style="zoom:67%;"><blockquote><p>回到Mendeley sync一下，出现该项，但是此时无法打开，如下图将你的论文添加：</p></blockquote><p><img src="/wen-xian-tu-shu-zi-yuan-sou-suo-yu-shi-yong-guan-li/image-20201012160634578.png" alt="image-20201012160634578"></p><h2 id="SCI一区、二区、影响因子？"><a href="#SCI一区、二区、影响因子？" class="headerlink" title="SCI一区、二区、影响因子？"></a>SCI一区、二区、影响因子？</h2><p>一般SCI论文分四个区，一区都是国际顶级期刊，二区次之，三区和四区是一般的SCI期刊，有两种，一种是web of science的JCR（journal citation report）分区，在web of science 搜索论文下面会有按钮显示期刊影响力。另一种是中科院分区，请在高校或中科院内登录<a href="http://www.fenqubiao.com/">http://www.fenqubiao.com</a>。</p><p>影响因子（英文：Impact Factor），简称IF，是汤森路透（Thomson Reuters）出品的期刊引证报告（Journal Citation Reports，JCR）中的一项数据。 即某期刊前两年发表的论文在该报告年份（JCR year）中被引用总次数除以该期刊在这两年内发表的论文总数。这是一个国际上通行的期刊评价指标。影响因子现已成为国际上通用的期刊评价指标，它不仅是一种测度期刊有用性和显示度的指标，而且也是测度期刊的学术水平，乃至论文质量的重要指标。影响因子是一个相对统计量。</p><h2 id="图书搜索"><a href="#图书搜索" class="headerlink" title="图书搜索"></a>图书搜索</h2><blockquote><p><strong>虫部落快搜</strong>：<a href="https://search.chongbuluo.com/%EF%BC%8C%E9%9B%86%E5%90%88%E4%BA%86%E5%BE%88%E5%A4%9A%E6%90%9C%E7%B4%A2%EF%BC%8C%E5%8C%85%E6%8B%AC**%E9%B8%A0%E6%91%A9%E6%90%9C%E4%B9%A6">https://search.chongbuluo.com/，集合了很多搜索，包括**鸠摩搜书</a>**</p><p><strong>Z-Library：</strong><a href="https://1lib.net/%EF%BC%8C**%E7%9C%9F%E7%9A%84%E6%98%AF%E5%AE%9D%E8%97%8F">https://1lib.net/，**真的是宝藏</a>**</p><p>Library Genesis：<a href="https://libgen.lc/">https://libgen.lc/</a></p></blockquote><h2 id="如何快速有效的读论文？"><a href="#如何快速有效的读论文？" class="headerlink" title="如何快速有效的读论文？"></a>如何快速有效的读论文？</h2><h3 id="误区？"><a href="#误区？" class="headerlink" title="误区？"></a>误区？</h3><p><strong>从头到尾恨不得嚼透每个单词</strong>，读完后束之高阁让记忆随风飘摇，<strong>无选择的精读</strong></p><p>读论文和学英语区分开！！！读论文不是来学英语！<strong>那些在阅读中遇到的生单词（学术词汇除外）真的会对通篇的理解形成严重障碍吗？</strong></p><p><strong>只看不记</strong></p><h3 id="如何读一篇论文？"><a href="#如何读一篇论文？" class="headerlink" title="如何读一篇论文？"></a>如何读一篇论文？</h3><img src="/wen-xian-tu-shu-zi-yuan-sou-suo-yu-shi-yong-guan-li/image-20201103091823835.png" alt="论文结构" style="zoom:67%;"><p><img src="/wen-xian-tu-shu-zi-yuan-sou-suo-yu-shi-yong-guan-li/image-20201103092224607.png" alt="是否值得读"></p><p><img src="/wen-xian-tu-shu-zi-yuan-sou-suo-yu-shi-yong-guan-li/image-20201103092352775.png" alt="如何读"></p><p><img src="/wen-xian-tu-shu-zi-yuan-sou-suo-yu-shi-yong-guan-li/image-20201103092602961.png" alt="如何读"> 很多人对于做笔记到底写什么各执一词，这里我觉得每个人在科研的不同阶段对于文章的关注点可能不尽相同，所以很难一言以蔽之。</p><p>比如<strong>初涉科研的小白</strong>，文献阅读能力和论文写作能力比较欠缺，那么可以在<strong>笔记中[用一句话（英文）概括实验、结果、讨论章节中的每一段内容，组成一个阅读笔记]。</strong>这样既可以锻炼英语书写表达能力，也可以逼迫自己[在理解的基础上进行一定量的输出，这是一个加深理解和记忆的过程」。<br>对于<strong>阅读科研文献比较熟练，有一些科研工作经历的人来说</strong>，这个笔记的内容可能是<strong>文中某个新的实验方法、异于其他研究的实验条件、阅读时自己的新想法等等</strong>。精读文献并认真做笔记并不代表读者对于这篇文章的消化过程就此终止，我个人觉得优秀的科研论文、大牛的研究著作依然是常读常新，每位从事科研学习和工作的人在不同的时期都能从中汲取养分。</p><h3 id="总结汇报"><a href="#总结汇报" class="headerlink" title="总结汇报"></a>总结汇报</h3><ul><li>基本信息(标题、作者、作者单位、发表期刊/会议、发表时间)</li><li>核心问题</li><li>主要思路/创新</li><li>存在问题与改进思路</li></ul><h3 id="技巧？"><a href="#技巧？" class="headerlink" title="技巧？"></a>技巧？</h3><p>review论文</p><p>与论文相应的PPT、博客、视频、课程、代码等</p><p>有代码的文章重点看！有代码的话, 一方面便于自己将一些核心思想或者基础知识理解透彻; 另一方面, 将来写文章,做对比试验也方便</p><p>英文论文中，<strong>每段话第一句一般都是主旨句</strong>，剩下内容都是围绕第一句展开（自己写论文时也可以这样，先写一段中心句，下面内容围绕它展开）</p>]]></content>
      
      
      <categories>
          
          <category> 软件使用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mendeley </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Typora使用问题</title>
      <link href="typora-shi-yong-wen-ti/"/>
      <url>typora-shi-yong-wen-ti/</url>
      
        <content type="html"><![CDATA[<h2 id="无序列表如何退出？"><a href="#无序列表如何退出？" class="headerlink" title="无序列表如何退出？"></a>无序列表如何退出？</h2><p>左上角的选项很迷，可以使用源代码模式退出，还可以按一下退格两下enter退出</p><h2 id="公式块编辑常见命令？"><a href="#公式块编辑常见命令？" class="headerlink" title="公式块编辑常见命令？"></a>公式块编辑常见命令？</h2><blockquote><p>版权声明：本文为博主原创文章，遵循<a href="http://creativecommons.org/licenses/by-sa/4.0/"> CC 4.0 BY-SA </a>版权协议，转载请附上原文出处链接和本声明。</p><p>本文链接：<a href="https://blog.csdn.net/mingzhuo_126/article/details/82722455">https://blog.csdn.net/mingzhuo_126/article/details/82722455</a> </p></blockquote><p><a href="https://blog.csdn.net/u013914471/article/details/82973812">https://blog.csdn.net/u013914471/article/details/82973812</a></p><p>\in 属于 \notin 不属于 \换行  \{ \} 打大括号 \sim打波浪线</p><h2 id="emoji表情md编写？"><a href="#emoji表情md编写？" class="headerlink" title="emoji表情md编写？"></a>emoji表情md编写？</h2><p>参考大神博客：<a href="https://sunhwee.com/posts/a927e90e.html">https://sunhwee.com/posts/a927e90e.html</a></p><h3 id="Markdown设置？"><a href="#Markdown设置？" class="headerlink" title="Markdown设置？"></a>Markdown设置？</h3><p>可以在偏好设置的Markdown处设置内联公示、代码行号、公式序号</p><h2 id="括号问题"><a href="#括号问题" class="headerlink" title="括号问题"></a>括号问题</h2><p>只有中文括号可以显示在博客中</p>]]></content>
      
      
      <categories>
          
          <category> 软件使用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> typora </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>颜色恒常性之&lt;&lt;A Multi-Hypothesis Approach to Color Constancy&gt;&gt;</title>
      <link href="yan-se-heng-chang-xing-zhi-mhcc/"/>
      <url>yan-se-heng-chang-xing-zhi-mhcc/</url>
      
        <content type="html"><![CDATA[<h2 id="论文思路"><a href="#论文思路" class="headerlink" title="论文思路"></a>论文思路</h2><p>论文：&lt;&lt;A Multi-Hypothesis Approach to Color Constancy&gt;&gt;</p><h3 id="Title-amp-Abstract-amp-Conclusion"><a href="#Title-amp-Abstract-amp-Conclusion" class="headerlink" title="Title&amp;Abstract&amp;Conclusion"></a>Title&amp;Abstract&amp;Conclusion</h3><blockquote><p>Multi-Hypothesis？</p></blockquote><p><strong>多假设都有什么假设？</strong></p><ol><li>Under the prevalent assumption that the scene is illuminated by a single or dominant light source, the observed pixels of an image are typically modelled using the physical model of Lambertian image formation captured under a trichromatic photosensor:</li><li>we assume that the color of the light and the surface reflectance are independent.</li><li>the function modelling the prior also depends on factors such as the environment (indoor / outdoor), the time of day, ISO etc. However, the size of currently available datasets prevent us from modelling more complex proxies.</li></ol><blockquote><p><strong>Our likelihood estimator</strong> learns to answer <strong>a camera-agnostic question</strong> and thus enables <strong>effective multi-camera training</strong> by disentangling illuminant estimation from the supervised learning task.</p><p>learning from image samples that were <strong>captured by multiple cameras</strong></p></blockquote><p><strong>相机无关和多相机图片训练到底是如何实现的？</strong></p><p>只是这个似然估计器与相机无关，多个相机获得多个数据集，对每个数据集利用KMeans找出候选光源，然后都喂入网络，实现了多相机图片训练</p><h3 id="Figure"><a href="#Figure" class="headerlink" title="Figure"></a>Figure</h3><p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201019104708991.png" alt="Figure1"></p><blockquote><p><strong><u>（d）use an illuminant candidate set per camera</u></strong>. <strong><u>[ r/g ,b/g ]</u></strong></p></blockquote><p><strong>每个摄像机获得一个候选集吗？最后是如何训练的？对于每个摄像机的候选集，是如何选取划分的？</strong></p><p>每个摄像机有自己的一个照片集，对这里的图片进行分类，每个摄像机获得一个候选集。训练应该就是将这些候选集都喂入。</p><p><strong>[r/g,b/g]这个图如何读?</strong></p><p>图上一个点应该是代表一个光源，<strong>为了将三维降成二维？</strong>，显示了光源的分布</p><p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201018164327078.png" alt="pipeline"></p><p><strong>如果现在有一张待还原的照片，如何还原，都要生成n个候选光源吗？怎么生成？</strong></p><p>n个候选光源已经生成好了，现在训练网络是需要不同光源的权重配比不同！所以到时候对于待还原照片，还是相同的过程，用每个候选光源修正图片，然后放入网络，得到权重。</p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>$$<br>\rho_{k}(X)=\int_{\Omega}E(\lambda)S(\lambda,X)C_{k}(\lambda)d\lambda\quad\quad\quad k\in{R,G,B}<br>$$</p><p><strong>为什么要积分？</strong></p><p>积分是因为比如绿色，打个比方是755~760这个频段的波长共同作用生成的，所以需要进行积分。<br>$$<br>\rho_{k}^E=\int_{\Omega}E(\lambda)C_{k}(\lambda)d\lambda\quad\quad\quad k\in{R,G,B}<br>$$</p><p>The goal of computational CC then becomes estimation of the <u><strong>global illumination color</strong></u>$\rho_k^E$？</p><p><strong>为什么变成了这个形式？</strong></p><p>对于物体成像的颜色，$S(\lambda,X)$表示物体本身的影响，$\rho_k^E$就表示光源的影响。后边我们说的光源就是指$\rho_k^E$整体。</p><blockquote><p>due to the <strong>ill-posed</strong> nature of the problem, <strong>multiple illuminant solutions are often possible with varying probability</strong>.</p></blockquote><p><strong>什么是ill-posed ？</strong></p><p>适定问题是指定解满足下面三个要求的问题：① 解是存在的；② 解是唯一的；③ 解连续依赖于定解条件，即解是稳定的。这三个要求中，只要有一个不满足，则称之为不适定问题</p><blockquote><p>avoid <u><strong>distribution shift</strong></u> and <u><strong>resulting domain gap problems</strong></u> [1, 41, 22], associated with camera specific training, and propose a well-founded strategy to leverage multiple data.</p></blockquote><p><strong>什么是distributin shift&amp;domain gap？</strong></p><p><strong>distribution shift</strong>: <a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a> </p><p>**domain gap problem:**<a href="https://zhuanlan.zhihu.com/p/195704051">https://zhuanlan.zhihu.com/p/195704051</a></p><blockquote><p>Principled combination of datasets is of high value for learning based color constancy given the typically small nature of individual color constancy datasets (on the order of only hundreds of images).</p></blockquote><p><strong>这句话在说啥？</strong></p><blockquote><p>We provide <strong><u>a training-free model adaptation strategy for new cameras</u></strong>.</p></blockquote><p><strong>加入一个新的摄像机，如何改进模型？</strong></p><p>新加入一个摄像机，只要这个摄像机的候选光源已知了，就可以直接拿这个网络训练了，所以不需要再重新训练或微调。</p><h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><h4 id="Bayesian-framework"><a href="#Bayesian-framework" class="headerlink" title="Bayesian framework"></a>Bayesian framework</h4><blockquote><p> They <strong>model the prior of the illuminant and the surface reflectance as a <u>truncated multivariate normal distribution</u> on the weights of a linear model</strong></p></blockquote><p><strong>什么是truncated multivariate normal distribution on the weights of a linear model?</strong></p><p>截断正态分布：指限制变量x取值范围(scope)的一种分布。例如，限制x取值在0到50之间，即{0&lt;x&lt;50}。</p><blockquote><p>Bayesian works [44, 23], <strong>discretise the illuminant space</strong> and <strong>model the surface reflectance priors</strong> by <u><strong>learning real world histogram frequencies</strong></u>;</p></blockquote><p>通过学习真实世界的直方图频率，来离散化光源空间和对表面反射率进行先验建模。<strong>可以查看它如何学习真实世界的直方图频率应用到肤色定级。</strong></p><blockquote><p>in [44] the prior is modelled as a <strong><u>uniform distribution over a subset of illuminants</u></strong> while [23] uses the <strong><u>empirical distribution of the training illuminants</u></strong>.</p></blockquote><p><strong>对于光源概率44和23有两种想法：直接建模成均匀分布和利用训练光源的经验分布。</strong></p><p>经验分布函数：<a href="https://zh.wikipedia.org/zh-hans/%E7%BB%8F%E9%AA%8C%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0#:~:text=%E7%BB%8F%E9%AA%8C%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0%EF%BC%88%E8%8B%B1%E8%AA%9E%EF%BC%9Aempirical,%E6%A0%B7%E6%9C%AC%E6%89%80%E5%8D%A0%E7%9A%84%E6%AF%94%E4%BE%8B%E3%80%82">https://zh.wikipedia.org/zh-hans/%E7%BB%8F%E9%AA%8C%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0#:~:text=%E7%BB%8F%E9%AA%8C%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0%EF%BC%88%E8%8B%B1%E8%AA%9E%EF%BC%9Aempirical,%E6%A0%B7%E6%9C%AC%E6%89%80%E5%8D%A0%E7%9A%84%E6%AF%94%E4%BE%8B%E3%80%82</a></p><h4 id="Fully-supervised-methods"><a href="#Fully-supervised-methods" class="headerlink" title="Fully supervised methods"></a>Fully supervised methods</h4><blockquote><p>frame color constancy as a classification problem：CCC and FCCC using a color space that identifies image re-illumination with a histogram shift. </p></blockquote><p><strong>CCC和FCCC待看</strong></p><h4 id="Multi-device-training"><a href="#Multi-device-training" class="headerlink" title="Multi-device training"></a>Multi-device training</h4><blockquote><p> [37] affords <strong>fast adaptation to previously unseen cameras</strong>, and robustness to changes in capture device by leveraging annotated samples across different cameras and datasets in a <strong><u>meta-learning</u></strong> framework</p></blockquote><p><strong>meta-learning?</strong></p><blockquote><p>A recent approach [8], makes an assumption that sRGB images collected from the web are well white balanced, therefore, they apply <strong><u>a simple de-gamma correction</u></strong> to approximate an <strong><u>inverse tone mapping</u></strong> and then find achromatic pixels with a CNN to predict the illuminant. </p></blockquote><p><strong>de-gamma correction？inverse tone mapping？</strong></p><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><blockquote><p>Let y = (yr, yg, yb) be a pixel from an input image Y in <strong><u>linear RGB space</u></strong>. </p></blockquote><p><strong>线性RGB空间？</strong></p><p><a href="https://www.cnblogs.com/guanzz/p/7416821.html">https://www.cnblogs.com/guanzz/p/7416821.html</a></p><blockquote><p>We model the global illumination, Eq. (2), with the <strong><u>standard linear model</u></strong> [51] such that each pixel y is the product of the surface reflectance r = (rr, rg, rb) and a global illuminant ? = (?r, ?g, ?b) shared by all pixels such that</p></blockquote><p><strong>标准线性模型？</strong></p><p>可能就是三个函数相乘得到一个线性模型？</p><blockquote><p>we propose to frame the CC problem with a <strong><u>probabilistic generative model</u></strong> with unknown surface re- flectances and illuminant</p></blockquote><p><strong>概率生成模型？</strong></p><p><strong>公式推导</strong></p><p>$$<br>P(l|Y)=\frac{P(Y|l)P(l)}{P(Y)}<br>$$</p><p>$$<br>P(Y|l)=\int_rP(Y|l,R=r)P(R=r)dr<br>$$</p><p>公式(4)利用了全概率公式<br>$$<br>\int_rP(Y|l,R=r)P(R=r)dr=P(R=diag(l)^{-1}Y)<br>$$<br>公式(5),由于$y_k=r_k\cdot l_k\quad\quad k\in R,G,B$ 所以当且仅当$R=diag(l)^{-1}$时，才能生成Y,所以此时$P(Y|l,R=diag(l)^{-1})=1$,$P(Y|l,R=else)=0$,所以只剩下一项$P(R=diag(l)^{-1}Y)$</p><blockquote><p>We highlight that learned affine transformation parameters are training <strong>camera-dependent and provide further discussion</strong> on camera agnostic considerations in Section</p></blockquote><p><strong>为什么这个参数是摄像机依赖的？</strong></p><p>因为$B_l$是光源的先验估计，由公式二，全局光源由光源功率和接收函数决定。所以是摄像机依赖的。</p><blockquote><p>In order to estimate the illuminant  l*, we optimise the quadratic cost (minimum MSE Bayesian estimator), minimised by the mean of the posterior distribution:<br>$$<br>l^*=\int_l l\cdot P(l|Y)dl<br>$$</p></blockquote><p><strong>为什么是这个公式？</strong></p><p>我们现在获得了n个光源$l_0、l_1\cdots l_n$和n个概率$p_0、p_1\cdots p_n$,我们如何确定最优光源$l^*$?该论文就是简单使MSE最小，当$l^*$是期望时MSE最小，如果你忘了为啥了可以列个二次函数求导！</p><blockquote><p>We require <strong>a differentiable method</strong> in order to train our model end-to-end, and therefore the use of <strong>a simple Maximum a Posteriori （MAP）inference strategy is not possible</strong>. Therefore to estimate the illuminant l*, we use the minimum mean square error Bayesian estimator, which is minimised by the posterior mean of l (c.f. Eq. (6))”</p></blockquote><p><strong>为什么MAP不行？</strong></p><p>因为反向传播我们是需要求导的，而如果用极大后验估计求$l^*$，似然是用网络得到的，是没有办法求导的；所以我们需要采取一个办法他不需要对网络那一块求导就能得到$l^*$，所以使用最简单的方法-使MSE最小，$l^*$就是各个候选光源的期望。<br>$$<br>l^*=\sum_{i=1}^n l_i\cdot softmax(log(P(l_i|Y)))\<br>=\frac{1}{\sum e^{log(P(l_i|Y))}}\sum_{i=1}^nl_i\cdot e^{log(P(l_i|Y))}\<br>=\frac{1}{\sum P(l_i|Y)}\sum_{i=1}^nl_i\cdot P(l_i|Y)<br>$$</p><blockquote><p>The resulting vector $l^*$ is l2-normalised.</p></blockquote><p><strong>l2-normalised？</strong></p><p><a href="https://blog.cweihang.io/ml/trick/l2_normalize">https://blog.cweihang.io/ml/trick/l2_normalize</a></p><p>？？？</p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><h3 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h3><p><strong>1x1 Conv?</strong></p><p>也叫Network in Network,添加了一个非线性运算，可用于压缩信道或增加信道</p><p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201027160655612.png" alt="吴恩达课程"></p><blockquote><p>Towards reproducibility, and fair comparison, our suppplementary material provides the cross validation splits, used in the main paper, for multi-device training</p></blockquote><p><strong>Cross validation？</strong></p><p>交叉验证：<a href="https://zh.wikipedia.org/zh-hans/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89">https://zh.wikipedia.org/zh-hans/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89</a></p><h2 id="个人思路"><a href="#个人思路" class="headerlink" title="个人思路"></a>个人思路</h2><h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a><strong>创新点</strong></h3><ol><li><p>提供了最佳光源的多个可能性</p></li><li><p>采用分类的方法而不是回归</p></li><li><p>设计的网络是摄像机无关的，可以使用多设备数据集进行训练，对于新型设备的泛化性比较好</p></li></ol><h3 id="多假设"><a href="#多假设" class="headerlink" title="多假设"></a>多假设</h3><ol><li>Under the prevalent assumption that the scene is illuminated by a single or dominant light source, the observed pixels of an image are typically modelled using the physical model of Lambertian image formation captured under a trichromatic photosensor:</li><li>we assume that the color of the light and the surface reflectance are independent.</li><li>the function modelling the prior also depends on factors such as the environment (indoor / outdoor), the time of day, ISO etc. However, the size of currently available datasets prevent us from modelling more complex proxies.</li></ol><h3 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h3><p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201029093444705.png" alt="朗伯特模型"></p><p>对此公式可以进行简化，原式$=S(X)\int_\Omega E(\lambda)C_k(\lambda)d\lambda\quad k\in {R,G,B}$</p><p><strong>公式简化的两种解释</strong></p><p>1：相机R、G、B光谱敏感函数是<strong>狄拉克δ函数</strong>，就是说，每个相机的光敏R、G、B三通道每个只能感应波长的一个值</p><p>2：RGB的能感知的光谱构成可见光的一个划分,$Sup(Rc)$支撑集表示Rc能感知的光谱。对于每个支撑集，<strong>假设反射率函数与波长无关</strong></p><p>我们对该公式用如下形式表示：$y_k=r_k\cdot l_k \quad k\in{R,G,B}$ </p><p>已知一个参数$y_k$,即<strong>我们已经知道的照片</strong>，求两个参数$r_k,l_k$,分别为<strong>物体对成像的影响</strong>和<strong>光照对成像的影响</strong>。</p><p>已知一个参数，求两个参数，约束过少。</p><p><strong>琅伯特模型经典假设：</strong></p><p>  1：<strong>固定相机拍摄的固定场景物体颜色的改变只能由改变光照实现</strong></p><p>  2：<strong>固有物体反射率图像可以通过过滤光照颜色来实现</strong></p><p>过滤光照颜色即除$l_k$,即$r_k=\frac{y_k}{l_k}$,只要获得$r_k$再乘以标准光照，就能获得白平衡图像。所以我们需要做的就是<strong>估计光照</strong>$l_k$</p><p>之前的<strong>回归方法</strong>，是利用网络直接学习$l_k$,这样提供一个点估计，但是<strong>颜色还原问题本身具有不适定性</strong>，可能有多个$l_k$符合条件,每个$l_k$的概率不同。</p><p>所以作者想的是对于图像数据集利用K_means对光源进行聚类，获得的聚类中心点就是候选的光源，也就是多个可能性，解决了上面回归方法的单个点估计的考量。具体做法见下图:</p><p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201029101605001.png" alt="网络架构"><br>$$<br>P(l|Y)=\frac{P(Y|l)P(l)}{P(Y)}<br>$$</p><p>$$<br>P(Y|l)=\int_rP(Y|l,R=r)P(R=r)dr=P(R=diag(l)^{-1}Y)<br>$$</p><p>第一步变换应用了<strong>全概率公式</strong></p><p><strong>第二步变换</strong>由于$y_k=r_k\cdot l_k\quad\quad k\in R,G,B$ 所以当且仅当$R=diag(l)^{-1}$时，才能生成Y,所以此时$P(Y|l,R=diag(l)^{-1})=1$,$P(Y|l,R=else)=0$,所以只剩下一项$P(R=diag(l)^{-1}Y)$</p><p>所以我们这个<strong>CNN网络</strong>为$f^W$,则$log(P(Y|l))=log(P(R=diag(l)^{-1}Y))=f^W(diag(l)^{-1}Y)$，即每个候选光源是场景光源的概率。</p><p>另外，在实际场景中，<strong>不同候选光源出现的概率</strong>是不同的，即$P(l)$不同,基于此我们添加了两个参数$G_l、B_l$，分别为增益系数和$log(P(l))$<br>$$<br>log(P(l|Y))=Gl\cdot log(P(Y|l))+B_l<br>$$<br>而引入这两个参数会带来问题！</p><p>本来我们的网络是<strong>摄像机无关</strong>的(即没有$log(P(l))$ )，为什么说摄像机无关呢？</p><p>多个相机获得多个数据集，对每个数据集利用KMeans找出候选光源，然后都喂入网络，实现了多相机图片训练。假设我们现在引入了 一个新的摄像机，并获得一个该摄像机的数据集，我们要做的就是对该摄像机进行K-Means，然后测试时，对于一张图片 ，我们现在修正图片需要做的是之前的加上新的候选光源一起修正分别得到概率就行，不需要重新训练或微调。</p><p>而引入$log(P(l))$,之前我们的公式表明，<strong>全局光源由光源功率和接收函数决定</strong>，这个时候就必然引入了摄像机关联。</p><p>所以如果要多设备训练的话，就不引入这两个参数，这样虽<strong>然降低了灵活性，少了两个学习参数，但是现在可用的数据集变多了，大数据集弥补了</strong>。</p><p>我们现在获得了n个光源$l_0、l_1\cdots l_n$和n个概率$p_0、p_1\cdots p_n$,我们如何确定最优光源$l^*$?</p><p>首先<strong>简单的MAP是不行的</strong>，因为反向传播我们是需要求导的，而如果用极大后验估计求$l^*$，似然是用网络得到的，是没有办法求导的；</p><p>所以我<strong>们需要采取一个办法他不需要对网络那一块求导就能得到</strong>$l^*$，该论文就是利用简单的线性组合获得$l^*$，使MSE最小，当$l^*$是期望时MSE最小，如果你忘了为啥了可以列个二次函数求导！<br>$$<br>l^*=\sum_{i=1}^n l_i\cdot softmax(log(P(l_i|Y)))\<br>=\frac{1}{\sum e^{log(P(l_i|Y))}}\sum_{i=1}^nl_i\cdot e^{log(P(l_i|Y))}\<br>=\frac{1}{\sum P(l_i|Y)}\sum_{i=1}^nl_i\cdot P(l_i|Y)<br>$$<br>上式<strong>使用softmax是使概率归一。</strong></p><p><strong>CNN结构：</strong></p><p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201029112002665.png" alt="Architecture"></p><h3 id="失败案例"><a href="#失败案例" class="headerlink" title="失败案例"></a>失败案例</h3><p><strong>1 GT在光源分布外</strong></p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201029112126449.png" alt="failure-1" style="zoom:50%;"><p>因为是线性内插，分布外的点得不到</p><p><strong>2 打破了单一光源假设</strong></p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201029113004477.png" alt="failure-2" style="zoom:67%;"><p><strong>3 问题的不适定本性</strong></p><img src="/yan-se-heng-chang-xing-zhi-mhcc/image-20201029113057076.png" alt="failure-3" style="zoom: 80%;"><p>学到了看起来非常可信的白平衡图片，认为石头是白的，其实石头是黄的</p>]]></content>
      
      
      <categories>
          
          <category> Color Constancy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CC/AWB </tag>
            
            <tag> Bayes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人脸识别与肤色分类及dlib库</title>
      <link href="ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/"/>
      <url>ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/</url>
      
        <content type="html"><![CDATA[<h2 id="人脸识别pipeline"><a href="#人脸识别pipeline" class="headerlink" title="人脸识别pipeline"></a>人脸识别pipeline</h2><p>论文参考《Modern Face Recognition with Deep Learning》，其实整篇论文与<a href="https://link.zhihu.com/?target=https://medium.com/@ageitgey?source=post_header_lockup">Adam Geitgey</a>写的文章一致，中文链接如下：<a href="https://zhuanlan.zhihu.com/p/24567586">https://zhuanlan.zhihu.com/p/24567586</a></p><h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-0.png" alt="人脸识别流程图" style="zoom:67%;"><h3 id="Step-1-arrow-heading-down-：人脸检测-Face-Detection"><a href="#Step-1-arrow-heading-down-：人脸检测-Face-Detection" class="headerlink" title="Step 1:arrow_heading_down:：人脸检测-Face Detection"></a>Step 1<span class="github-emoji"><span>⤵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2935.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>：人脸检测-Face Detection</h3><blockquote><p>​    我们使用**方向梯度直方图(HOG)**来标定人脸位置。</p><p>​    要在一张图片中找到脸，我们首先将图像转换为黑白，因为我们并不需要颜色数据来找到脸。</p><p>​    然后，我们将查看图片中的每一个像素。 对于单个像素，我们也要查看它周围的其他像素。我们的目标是找出并比较当前像素与直接围绕它的像素的深度。 然后我们要画一个箭头来代表图像变暗的方向，对图片中的每一个像素重复这个过程，最终每个像素会被一个箭头取代。这些箭头被称为梯度（gradients），它们能显示出图像上从明亮到黑暗的流动过程。</p><p>​    为了获取更泛化的特征，将图像分隔成16x16的小方块，统计每个主方向上有多少个梯度，最后用梯度最多的主方向代替原来小方块。<br>HOG主要优点就是减轻了图像明暗度的影响，获得的是像素之间的相对特征。</p></blockquote><p><strong>代码注意：</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#dlib  get_frontal_face_detector():生成HOG面部检测器 detector(image,1)1表示采样次数，越大识别出来的脸越多，小脸也能识别到，上采样也就是图像放大倍数</span><span class="token comment" spellcheck="true">#dlib.image_window：a gui window that can show image  win.set_image(image) </span><span class="token comment" spellcheck="true">#win.add_overlay(dlib.dlib.rectangle)：Add a list of rectangles to the image_window. They will be displayed as red boxes by default, but the color can be passed.</span><span class="token comment" spellcheck="true">#from skimage import io   io.imread()存储的图片是&lt;class 'ndarray'></span><span class="token comment" spellcheck="true">#'{}'.format 注意使用</span><span class="token comment" spellcheck="true">#enumrate    for i,data in enumerate():</span></code></pre><p><strong>图片示例：</strong></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014155202049.png" alt="Figure 1：一张人脸示例"></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014155225990.png" alt="Figure 2：HOG标定人脸位置示例"></p><h3 id="Step-II-arrow-heading-down-：人脸对齐-Face-Alignment"><a href="#Step-II-arrow-heading-down-：人脸对齐-Face-Alignment" class="headerlink" title="Step II:arrow_heading_down:：人脸对齐-Face Alignment"></a>Step II<span class="github-emoji"><span>⤵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2935.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>：人脸对齐-Face Alignment</h3><blockquote><p>把图片中的脸部分离出来之后，我们将试图扭曲每个图片，使得眼睛和嘴唇总是在图像中的样本位置（sample place）。 这将使我们在接下来的步骤中，更容易比较脸部之间的不同。这被称为人脸对齐任务。</p><p>我们使用一种称为面部特征点估计(face landmark estimation)的算法(使用由 瓦希德·卡奇米Vahid Kazemi和约瑟菲娜·沙利文Josephine Sullivan在2014 年发明的方法)。</p><p>这一算法的基本思路是找到 68 个人脸上普遍存在的特定点（称为特征点， landmarks）——包括下巴的顶部、每只眼睛的外部轮廓、每条眉毛的内部轮廓等。</p><p>获得眼睛和嘴巴的位置后，我们使用仿射变换使得眼睛和嘴巴向中间挪动到大致相同的位置，这将使我们的下一步更加准确。</p></blockquote><p><strong>tips：</strong></p><blockquote><p>将试图扭曲每个图片，使得眼睛和嘴唇总是在图像中的样本位置（sample place）</p><p>face landmark estimation:68 landmarks</p><p>旋转、缩放和错切(shear mapping)</p></blockquote><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-1.png" alt="shear mapping"></p><blockquote><p>水平错切：</p><p>Affine transformation：仿射变换，简单来说就是：一个能保持线和平行但是不保持距离和角度的几何变换(维基百科：<a href="https://en.wikipedia.org/wiki/Affine_transformation">https://en.wikipedia.org/wiki/Affine_transformation</a>)</p></blockquote><p><strong>代码注意：</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#_init_(*args, **kwargs)  *args:*args 用来将参数打包成tuple给函数体调用    **kwargs: **kwargs 打包关键字参数成dict给函数体调用</span><span class="token keyword">def</span> <span class="token function">function</span><span class="token punctuation">(</span>arg<span class="token punctuation">,</span><span class="token operator">*</span>args<span class="token punctuation">,</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>arg<span class="token punctuation">,</span><span class="token operator">*</span>args<span class="token punctuation">,</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>function<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span>a<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>b<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#dlib.shape_predictor(predictor_model)   Loads a shape_predictor from a file that contains the output of the train_shape_predictor() routine.</span><span class="token comment" spellcheck="true">#pose_predictor(image, face_rect)   #__call__(self: dlib.shape_predictor, image: array, box: dlib.rectangle) → dlib.full_object_detection</span><span class="token comment" spellcheck="true">#dlib.full_object_detection:This object represents the location of an object in an image along with the positions of each of its constituent parts  </span>  <span class="token comment" spellcheck="true">#__init__(self: dlib.full_object_detection, rect: dlib.rectangle, parts: object) → None </span>        <span class="token comment" spellcheck="true">#rect: dlib rectangle</span>        <span class="token comment" spellcheck="true">#parts: list of dlib.point, or a dlib.points object</span></code></pre><p><strong>图片示例:</strong></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014160336556.png" alt="Figure 3：68个特征点位置"></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014160355457.png" alt="Figure 4：对齐示例"></p><h3 id="Step-3-arrow-heading-down-面部编码-Face-Encoding"><a href="#Step-3-arrow-heading-down-面部编码-Face-Encoding" class="headerlink" title="Step 3:arrow_heading_down::面部编码-Face Encoding"></a>Step 3<span class="github-emoji"><span>⤵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2935.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>:面部编码-Face Encoding</h3><blockquote><p>我们利用resnet网络对大量人脸图片进行训练，每次训练要观察三个不同的脸部图像：1. 加载一张已知的人的面部训练图像;2. 加载同一个人的另一张照片;3. 加载另外一个人的照片。该网络最终可获得对人脸的128维特征值。</p></blockquote><p><strong>tips:</strong></p><blockquote><p>未知图片和已知图片循环比对，最简单但是数据量过大时太慢，不现实</p></blockquote><p><strong>图片示例</strong>:</p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014161438279.png" alt="训练示例"></p><h3 id="Step-4-arrow-heading-down-肤色分类-Race-Classification"><a href="#Step-4-arrow-heading-down-肤色分类-Race-Classification" class="headerlink" title="Step 4:arrow_heading_down::肤色分类-Race Classification"></a>Step 4<span class="github-emoji"><span>⤵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2935.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>:肤色分类-Race Classification</h3><blockquote><p>​    利用前面获得resnet网络模型，对LFWA+数据集的所有图片进行编码，利用简单的MLP(多层感知器),对所有编码进行训练，然后可以根据MLP对不同图片进行肤色分类，肤色分为三个等级，分别为Asian、White、Black。</p></blockquote><h2 id="相关库学习："><a href="#相关库学习：" class="headerlink" title="相关库学习："></a>相关库学习：</h2><p><strong>库地址：</strong></p><blockquote><p>gender&amp;face classification：<a href="https://github.com/wondonghyeon/face-classification">https://github.com/wondonghyeon/face-classification</a></p><p>face_recognition：<a href="https://github.com/ageitgey/face_recognition/">https://github.com/ageitgey/face_recognition/</a></p><p>dlib ：<a href="http://dlib.net/python/index.html">http://dlib.net/python/index.html</a> Python Api</p></blockquote><h3 id="face-recognition库"><a href="#face-recognition库" class="headerlink" title="face_recognition库"></a>face_recognition库</h3><p><strong>代码注意：</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#face_recognition api:https://github.com/ageitgey/face_recognition/blob/55b5c136292dcd4a1f5953f3eb3181235086efab/face_recognition/api.py#L92</span><span class="token comment" spellcheck="true">#基本就是对dlib库进行了再封装，用的方法也就是以上人脸识别pipeline的过程</span><span class="token comment" spellcheck="true">#compute_face_descriptor(self: dlib.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),uint8], face: dlib.full_object_detection, num_jitters: int=0L, padding: float=0.25) -> dlib.vector</span><span class="token comment" spellcheck="true">#Takes an image and a full_object_detection that references a face in that image and converts it into a 128D face descriptor. If num_jitters>1 then each face will be randomly jittered slightly num_jitters times, each run through the 128D projection, and the average used as the face descriptor. Optionally allows to override default padding of 0.25 around the face.</span></code></pre><h3 id="gender-amp-face-classification"><a href="#gender-amp-face-classification" class="headerlink" title="gender&amp;face classification"></a>gender&amp;face classification</h3><p><strong>tips:</strong></p><blockquote><p>代码基本就是调的face_recognition库，face_recognition库又是封装的dlib库</p><p>最关键的是使用的数据集LFWA+，73分类</p><p>128维特征值，使用的模型是dlib_face_recognition_resnet_model_v1.dat <a href="https://github.com/ageitgey/face_recognition_models/tree/master/face_recognition_models/models">https://github.com/ageitgey/face_recognition_models/tree/master/face_recognition_models/models</a> ，该模型是dlib使用resnet训练生成的</p></blockquote><p><strong>图片示例:</strong></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201012212241700.png" alt="image-20201012212241700"></p><h2 id="GUI编写"><a href="#GUI编写" class="headerlink" title="GUI编写"></a>GUI编写</h2><h3 id="tkinter"><a href="#tkinter" class="headerlink" title="tkinter"></a>tkinter</h3><blockquote><p>大神博客：<a href="https://sunhwee.com/posts/80fa3a85.html#toc-heading-15">https://sunhwee.com/posts/80fa3a85.html#toc-heading-15</a></p><p>API(推荐)：<a href="https://web.archive.org/web/20190524140835/https://infohost.nmt.edu/tcc/help/pubs/tkinter/web/index.html">https://web.archive.org/web/20190524140835/https://infohost.nmt.edu/tcc/help/pubs/tkinter/web/index.html</a></p><p>还可以使用ttk，各种基本组件会变得更好看一点，上面api也有，</p></blockquote><h3 id="关于tkinter界面下点击按钮未响应的解决办法？"><a href="#关于tkinter界面下点击按钮未响应的解决办法？" class="headerlink" title="关于tkinter界面下点击按钮未响应的解决办法？"></a>关于tkinter界面下点击按钮未响应的解决办法？</h3><blockquote><p>参考：<a href="https://blog.csdn.net/aheress/article/details/105059955?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param">https://blog.csdn.net/aheress/article/details/105059955?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param</a></p></blockquote><h3 id="展示："><a href="#展示：" class="headerlink" title="展示："></a>展示：</h3><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201019151603976.png" alt="检测前" style="zoom:50%;"><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201019151714317.png" alt="检测后" style="zoom:50%;">]]></content>
      
      
      <categories>
          
          <category> 人脸识别 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> face_recognition </tag>
            
            <tag> 肤色分类 </tag>
            
            <tag> tkinter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo-git-github博客搭建</title>
      <link href="hexo-git-github-bo-ke-da-jian/"/>
      <url>hexo-git-github-bo-ke-da-jian/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考：洪卫的博客教程<a href="https://sunhwee.com/posts/6e8839eb.html">https://sunhwee.com/posts/6e8839eb.html</a></p><p>参考：hexo-theme-matery主题<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md#%E9%85%8D%E7%BD%AE%E5%9F%BA%E6%9C%AC%E8%8F%9C%E5%8D%95%E5%AF%BC%E8%88%AA%E7%9A%84%E5%90%8D%E7%A7%B0%E8%B7%AF%E5%BE%84url%E5%92%8C%E5%9B%BE%E6%A0%87icon">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md#%E9%85%8D%E7%BD%AE%E5%9F%BA%E6%9C%AC%E8%8F%9C%E5%8D%95%E5%AF%BC%E8%88%AA%E7%9A%84%E5%90%8D%E7%A7%B0%E8%B7%AF%E5%BE%84url%E5%92%8C%E5%9B%BE%E6%A0%87icon</a></p><p>参考：过客～励む的博客<a href="https://yafine-blog.cn/posts/4ab2.html">https://yafine-blog.cn/posts/4ab2.html</a></p></blockquote><h2 id="按流程搭建遇到的问题："><a href="#按流程搭建遇到的问题：" class="headerlink" title="按流程搭建遇到的问题："></a>按流程搭建遇到的问题：</h2><h3 id="搭建hexo博客时，到了最后一步，hexo-s后只出现代码，而不是首页？"><a href="#搭建hexo博客时，到了最后一步，hexo-s后只出现代码，而不是首页？" class="headerlink" title="搭建hexo博客时，到了最后一步，hexo s后只出现代码，而不是首页？"></a>搭建hexo博客时，到了最后一步，hexo s后只出现代码，而不是首页？</h3><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012224004113.png" alt="错误代码"></p><p><strong>在npm install安装依赖时出现了错误</strong></p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012224051241.png" alt="错误为第10行"></p><p>仔细查看错误信息，我们不难发现是ejs出现了问题。我们可以先执行以下代码后再继续后续操作。</p><pre><code>npm install ejs@2.7.4 --ignore-scripts</code></pre><p><strong><em>注意：之后所有的Bash命令都在最后一个MyBlog文件夹下操作，也就是你之前安装hexo那个文件夹！</em></strong></p><h3 id="什么是github-io？"><a href="#什么是github-io？" class="headerlink" title="什么是github.io？"></a>什么是github.io？</h3><blockquote><p>官网的一句话来形容 Websites for you and your projects</p></blockquote><h3 id="购买个人域名之后打开失败？"><a href="#购买个人域名之后打开失败？" class="headerlink" title="购买个人域名之后打开失败？"></a>购买个人域名之后打开失败？</h3><blockquote><p>极有可能是你未设置域名解析！</p></blockquote><h3 id="写文章发布文章不生成文件夹及图片无法显示？"><a href="#写文章发布文章不生成文件夹及图片无法显示？" class="headerlink" title="写文章发布文章不生成文件夹及图片无法显示？"></a>写文章发布文章不生成文件夹及图片无法显示？</h3><h4 id="不生成文件夹？"><a href="#不生成文件夹？" class="headerlink" title="不生成文件夹？"></a>不生成文件夹？</h4><p>首先，新建博客一定要用hexo new post命令，不然很多信息识别不出来</p><p>然后将_config.yml文件中的post asset folder设置为true，之后会出现文件夹</p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012224940500.png" alt="设置为true"></p><h4 id="图片不显示？"><a href="#图片不显示？" class="headerlink" title="图片不显示？"></a>图片不显示？</h4><p>首先下载依赖</p><pre><code>npm install hexo-asset-image --save</code></pre><p>然后对于typora编辑，偏好设置为：</p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012225346785.png" alt="image-20201012225346785" style="zoom: 80%;"><p>然后图片编写时，使用相对路径，例如：</p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012225527582.png" alt="例子"></p><p><strong><em>另外注意：千万不要错误使用转义符’\‘!!!!</em></strong></p><h3 id="数学公式块无法正常显示？"><a href="#数学公式块无法正常显示？" class="headerlink" title="数学公式块无法正常显示？"></a>数学公式块无法正常显示？</h3><blockquote><p>后面配置了主题就可以了！</p><p>但是注意：<strong>数学公式中如果出现了连续两个{，中间一定要加空格！</strong></p></blockquote><h3 id="菜单导航配置在哪？"><a href="#菜单导航配置在哪？" class="headerlink" title="菜单导航配置在哪？"></a>菜单导航配置在哪？</h3><blockquote><p>菜单导航配置在themes/hexo-theme-matery/__config.yml</p></blockquote><h2 id="什么是TOC"><a href="#什么是TOC" class="headerlink" title="什么是TOC?"></a>什么是TOC?</h2><h3 id="什么是RSS订阅？"><a href="#什么是RSS订阅？" class="headerlink" title="什么是RSS订阅？"></a>什么是RSS订阅？</h3><blockquote><p>​        RSS也称为RSS订阅或RSS提要，博客和新闻网站的一个常见做法是联合其内容。Web联合是指来自网站的内容可供其他站点或远程应用程序使用。Web联合的最常用方法是使用称为<strong>ReallySimpleSyndication</strong>的协议。RSS是一种协议，允许网站将其内容或其部分内容提供给其他网站或应用程序。</p></blockquote><h3 id="DaoVoice"><a href="#DaoVoice" class="headerlink" title="DaoVoice?"></a>DaoVoice?</h3><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013144940429.png" alt="设置"></p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013144951426.png" alt="设置"></p><h3 id="新建文章模板修改失败？"><a href="#新建文章模板修改失败？" class="headerlink" title="新建文章模板修改失败？"></a>新建文章模板修改失败？</h3><blockquote><p>莫名其妙post.md上下都变成了两个—，奇怪</p></blockquote><h3 id="修改页脚"><a href="#修改页脚" class="headerlink" title="修改页脚?"></a>修改页脚?</h3><h3 id="修改社交链接？"><a href="#修改社交链接？" class="headerlink" title="修改社交链接？"></a>修改社交链接？</h3><h3 id="不蒜子？不蒜子访问量和人数无法区分问题？"><a href="#不蒜子？不蒜子访问量和人数无法区分问题？" class="headerlink" title="不蒜子？不蒜子访问量和人数无法区分问题？"></a>不蒜子？不蒜子访问量和人数无法区分问题？</h3><blockquote><p>是一个极简网页计数器</p></blockquote><h3 id="添加动漫人物"><a href="#添加动漫人物" class="headerlink" title="添加动漫人物?"></a>添加动漫人物?</h3><blockquote><p>由于一直要安包，不敢继续弄了</p></blockquote><h3 id="gitalk-error-not-found？"><a href="#gitalk-error-not-found？" class="headerlink" title="gitalk error not found？"></a>gitalk error not found？</h3><blockquote><p><del>既有可能是yml的设置错误！</del></p><p><del><strong>owner和admin都填写github用户名</strong>，<strong>repo填我们的博客github仓库名</strong></del></p><p>问题终于解决！</p><img src="/hexo-git-github-bo-ke-da-jian/image-20201018215249728.png" alt="config" style="zoom:80%;"><img src="/hexo-git-github-bo-ke-da-jian/image-20201018215408171.png" alt="outh app" style="zoom: 50%;"></blockquote><h3 id="yml、yaml格式不正确？"><a href="#yml、yaml格式不正确？" class="headerlink" title="yml、yaml格式不正确？"></a>yml、yaml格式不正确？</h3><blockquote><p>使用这个在线校验器校验：<a href="http://www.bejson.com/validators/yaml_editor/">http://www.bejson.com/validators/yaml_editor/</a></p></blockquote><h3 id="gitalk未找到相关issues？"><a href="#gitalk未找到相关issues？" class="headerlink" title="gitalk未找到相关issues？"></a>gitalk未找到相关issues？</h3><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013183732541.png" alt="URL"></p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013183843079.png" alt="回调函数"></p><blockquote><p>一定要<strong>使用https而不是http</strong></p><p>还是不行？？？</p><p>失败！</p></blockquote><h3 id="网站根目录在哪里？"><a href="#网站根目录在哪里？" class="headerlink" title="网站根目录在哪里？"></a>网站根目录在哪里？</h3><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013200031772.png" alt="网站根目录"></p><h3 id="如何删除文章："><a href="#如何删除文章：" class="headerlink" title="如何删除文章："></a>如何删除文章：</h3><p>先hexo clean，然后在直接删除，如果不hexo clean的话，还是会再生成。</p><h2 id="git学习"><a href="#git学习" class="headerlink" title="git学习:"></a>git学习:</h2><blockquote><p>廖雪峰git教程 <a href="https://www.liaoxuefeng.com/wiki/896043488029600">https://www.liaoxuefeng.com/wiki/896043488029600</a></p></blockquote><p>git add先将文件放到车里，git commit把一车的东西运往其他城市。</p><p>Git的<code>commit id</code>不是1，2，3……递增的数字，而是一个SHA1计算出来的一个非常大的数字，用十六进制表示。为什么<code>commit id</code>需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。</p><h2 id="js、ejs学习："><a href="#js、ejs学习：" class="headerlink" title="js、ejs学习："></a>js、ejs学习：</h2><blockquote><p>js:<a href="https://www.runoob.com/js/js-tutorial.html">https://www.runoob.com/js/js-tutorial.html</a></p></blockquote><p>JavaScript 是<strong>脚本语言，浏览器会在读取代码时，逐行地执行脚本代码</strong>。而对于传统编程来说，会在执行前对所有代码进行编译。</p><p>对象最好使用**.**来调用，防止方法调用失败！</p><h2 id="博客编写规范"><a href="#博客编写规范" class="headerlink" title="博客编写规范"></a>博客编写规范</h2><p><strong>不做内容的搬运工！</strong>而是</p><ol><li><strong>记录遇到的问题，只针对问题进行解答</strong></li><li><strong>对于组会汇报内容进行详细编写</strong></li></ol>]]></content>
      
      
      <categories>
          
          <category> 博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> git </tag>
            
            <tag> ejs </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
