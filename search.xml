<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>肤色分级与系统</title>
      <link href="fu-se-fen-ji-yu-xi-tong/"/>
      <url>fu-se-fen-ji-yu-xi-tong/</url>
      
        <content type="html"><![CDATA[<h2 id="论文阅读-lt-lt-Brief-overview-of-PANTONE-SkinTone-Guide-chart-in-CIEL-a-b-color-space-gt-gt"><a href="#论文阅读-lt-lt-Brief-overview-of-PANTONE-SkinTone-Guide-chart-in-CIEL-a-b-color-space-gt-gt" class="headerlink" title="论文阅读-<<Brief overview of PANTONE SkinTone Guide chart in CIEL*a*b* color space>>"></a>论文阅读-&lt;&lt;Brief overview of PANTONE SkinTone Guide chart in CIEL*a*b* color space&gt;&gt;</h2><h3 id="Title-amp-Keywords-amp-Abstract-amp-Conclusion"><a href="#Title-amp-Keywords-amp-Abstract-amp-Conclusion" class="headerlink" title="Title&amp;Keywords&amp;Abstract&amp;Conclusion"></a>Title&amp;Keywords&amp;Abstract&amp;Conclusion</h3><h4 id="CIEL-a-b-color-space"><a href="#CIEL-a-b-color-space" class="headerlink" title="CIEL*a*b* color space?"></a>CIEL*a*b* color space?</h4><blockquote><p><strong>颜色开发培训讲义</strong>：<a href="https://www.zhihu.com/column/cxqingzong-color">https://www.zhihu.com/column/cxqingzong-color</a>     <strong>这篇不能更赞</strong></p><p><strong>可见光谱:</strong></p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201014213348777.png" alt="可见光谱"></p><p>我们所说的颜色主要分两种：</p><p><strong>光源色（light source color）</strong>：来自发光体的颜色。如太阳，灯泡，led灯，等等。</p><p><strong>表面色（surface color</strong>）：不是来自发光体的物体色。物体本身不发光，但能看到物体的颜色，是因为这些物体能对来自于其他发光体的光的选择性的吸收和反射。</p><p>颜色也可以简单分为两大类：</p><p><strong>非彩色</strong>：黑白灰</p><p><strong>彩色</strong>：红黄蓝绿等</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201014210822647.png" alt="彩色与非彩色"></p><p><strong>颜色感知的三要素，光源，物体和观察者，缺一不可，缺少一个要素，我们看不到颜色，或者其中一个要素发生改变，我们看到的颜色都会不一样。</strong></p><p>不同光源性质是不一样的，有些光源会亮一点白一点，如太阳，或者就是太阳光，一天内不同时间段的太阳光也会有很大差异，导致在这些不同的光源下看相同一个颜色都会有很大差异.</p><p>所以我们在颜色开发或者颜色沟通交流的时候，会指定一个标准光源，这样能确保我们双方看颜色条件的一致性。我们比对颜色使用的光源都是有标准规定的光源。通常在下图所示的对色灯箱里看颜色。灯箱里面装有不同的常用光源。</p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201014215437189.png" alt="对色灯塔及常见光源" style="zoom: 67%;"><p><strong>Light sources：发光体（照明体）</strong>。泛指能发出光（可见光）的物体，如太阳，蜡烛，灯泡等。但是有些发光体发出的光是变化的不稳定的。例如太阳光，就算在同一天光照辐射都是不一样的，是变化的，更何况在不同的天气，不同的季节。所以很难用这些不稳定的光源来进行对颜色的描述和交流。</p><p><strong>lluminants：光源</strong>。是一个可以定量描述的发光体。是国际照明委员会 CIE（Commission Internationale de L’Eclairage）为了对颜色的评估和计算而定义了不同类型的，能用数学表（相对能量和波长)表示的标准光源。</p><p><strong>色温Color temperature是照明光学中用于定义光源颜色的一个物理量。光源的色温是以光源发光时所显现的颜色与一个绝对黑体被高温燃烧时所显现的颜色相一致时的燃烧温度来定义的，它的单位是绝对温度Kelvin开尔文【K】。</strong></p><p>开尔文与摄氏度的转换关系如下：</p><p><strong>K(开尔文）=273.15+T(摄氏度）</strong></p><p>K值越高，显现的颜色就愈趋向于白蓝色；K值越低，显现的颜色就愈趋向于黄红色。</p><p>开尔文认为，假定纯黑体，能够将落在其上的所有热量吸收，而没有损失，同时又能够将热量生成的能量全部以“光”的形式释放出来的话，它产生辐射最大强度的波长随温度变化而变化。</p><p><strong>显色指数color rendering index (CRI)</strong> :与标准的参考光源相比较，一个光源对物体颜色外貌所产生的效果。换句话说，是一个光源与标准光源（例如日光）相比较下在颜色辨认方面的一种测量方式。CRI是一种得到普遍认可的度量标准，也是目前评价与报告光源显色性的惟一途径。</p><p><strong>Ra</strong> <strong>=</strong> <strong>物体在某一光源照射下所显现的颜色 ÷ 物体本身所具有的颜色</strong>。</p><p>Ra表示某光源的显色指数。Ra愈接近100%，表明在该光源照射下，物体所显现的颜色与物体本身所具有的颜色的差异就愈小。</p><p><strong>标准光源</strong>的光谱要求如下：</p><p>（1）光源的<strong>色温必须是5000K-6500K</strong>，在这种光源色温下观察颜色的效果基本类似于中国大部分地区上午8点至10点，下午3点至5点的自然光下的观察效果。</p><p>（2）光源的<strong>显色指数Ra&gt;90</strong></p><p>光源的性质，可以通过<strong>光谱功率分布曲线（SPD）</strong>来描述。不同的光源有着不同的光谱功率分布曲线。光谱功率分布（SPD）的意思就是光源发出可见光的不同光谱波长（400nm~700nm）的功率是不同的。功率可以理解成强度的大小。</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015094547985.png" alt="常用光源的光谱功率分布曲线"></p><p>物体关于颜色的性质是对不同波长的电磁波的选择性吸收，所以我们用<strong>光谱反射率曲线</strong>来表达物体的这种性质。红色绿色蓝色的光谱反射率曲线的最大特征是，它有明显的波峰。波峰所在的位置的电磁波波长代表着这个物体的颜色。</p><p>但是黑白灰就不一样。物体之所以能够呈现出<strong>白色</strong>，是因为这个物体对<strong>不同波长的电磁波几乎都不吸收</strong>，所以都被反射出来。<strong>黑色</strong>跟白色刚好相反，黑色物体<strong>几乎完全吸收所有波长的电磁波</strong>，所以从黑色的光谱反射率曲线来看，所有波长的光谱的反射率都很低很低。</p><p>观察者人眼：</p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015095247048.png" alt="人眼观察黄光" style="zoom:67%;"><p>类似人眼三种视锥细胞对不同波长的光的响应，研究人员也得到一个标准观察者的三刺激值（x，y，z），作为测色仪辨别颜色的视锥细胞。通过这三个参数xyz，来描述一个颜色，也就是后面将要介绍的<strong>CIE-XYZ颜色空间</strong>。</p><p>我们将<strong>光源</strong>、<strong>物体</strong>和<strong>观察者</strong>这三要素的性质相乘，也就是光源的光谱功率分布曲线乘以物体的光谱反射率曲线乘以标准观察者，得到三个参数<strong>X，Y，Z</strong>（都是大写字母），不同的颜色，有着不同XYZ值。</p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015100147722.png" alt="CIEXYZ" style="zoom:80%;"><p>按照下图里的公式算出<strong>x</strong>（小写X），<strong>y</strong>（小写Y）。xyz值（小写）代表着XYZ（大写）的占比，这样三个参数缩减到两个参数，两个参数形成一个平面的二维颜色空间，也就是CIE-XYZ颜色空间。CIE XYZ颜色空间具有不均匀性。</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015100255681.png" alt="CIE-XYZ颜色空间"></p><p>不容易对颜色差异的大小进行判定，无法非常直观的判定这个颜色就是我需要的颜色，不知道这个颜色跟我需要的颜色的差异的大小。</p><p>我们把人眼感觉不出的色彩差别量（变化范围）叫做颜色的宽容量。颜色的宽容量反映在CIE xy色度图上即为两个色度点之间的距离。因为，每种颜色在色度图上是一个点，但对人的视感觉来说，当这种颜色的色度坐标位置变化很小时，人眼仍认为它是原来的颜色，感觉不出它的变化。所以，对视感觉效果来说，在这个变化的距离（或范围）以内的色彩差别量，在视觉效果上是等效的。对色彩复制和其它颜色工业部门来说这种位于人眼宽容量范围之内的色彩差别量是允许存在的。</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015220402922.png" alt="不同标准色度点的颜色宽容量"></p><p>CIE-L<em>a</em>b*颜色空间，跟之前介绍的孟塞尔颜色体系的颜色空间是一样，是三维空间中立体的球形。空间中有三个维度，形成三个互相垂直的轴，分别是：</p><ul><li>L*轴：从上到下；<strong>表示明度</strong>，范围由0到100，表示颜色从深（黑）到浅（白）。</li><li>a*轴：从左到右；<strong>表示红绿</strong>，数值变化由正到负，表示颜色从红（正）到绿（负）。a值越大颜色越红，a值越小颜色越绿。</li><li>b*轴：从里到外。<strong>表示黄蓝</strong>，数值变化由正到负，表示颜色从黄（正）到蓝（负）。b值越大颜色越黄，b值越小颜色越蓝。</li><li><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015100941807.png" alt="CIE-L*a*b*"></li></ul><p>两个颜色之间的差异大小。引入一个概念——色差<strong>△E</strong>。两个颜色的差异大小，就是这两个颜色的在颜色空间上两个点的距离。色差的计算公式如下：</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015100802146.png" alt="色差的计算公式"></p><p>常见颜色空间介绍：<a href="https://blog.csdn.net/JiangHui1211/article/details/84592774?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param">https://blog.csdn.net/JiangHui1211/article/details/84592774?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param</a></p><p>在<strong>RGB颜色空间</strong>，任意色光F都可以用RGB三种颜色不同分量的相加混合而成：F=r[R]+g[G]+b[B]。</p><p><strong>一般我们读取图片获得的三维矩阵是RGB空间</strong></p><p>色度学规则：<br>　　(1)通过R,G,B这三种颜色能产生任何颜色，并且这三种颜色混合后产生的颜色是唯一的。<br>　　(2)如果两个颜色相等，这三个颜色分量再乘以或者除以相同的数，得到的颜色仍然相等。<br>　　(3)混合色的亮度等于每种颜色亮度的和。</p><p>RGB颜色空间的均匀性非常差，且两种颜色之间的知觉差异色差不能表示为该颜色空间中两点间的距离，但是利用线性或非线性变换，则可以从RGB颜色空间推导出其他的颜色特征空间。</p><p><strong>CMYK模式</strong>俗称四色打印模式，是最佳的打印模式。</p><p><strong>HSV颜色空间</strong>：感觉和孟塞尔颜色体系很像。HSV即色相(Hue)、饱和度(Saturation)、明度(Value)，又称HSB(B即Brightness)。</p><p>RGB和CMYK<strong>面向硬件</strong>，可用于<strong>图片编码</strong>；HSV面向用户，可用于<strong>图片编辑软件</strong>。</p><p><strong>sRGB色彩空间</strong>（standard Red Green Blue，标准红绿蓝色彩空间）是惠普与微软于1996年一起开发的用于显示器、打印机以及因特网的一种标准RGB色彩空间。这种标准得到了W3C、Exif、英特尔、Pantone、Corel以及其它许多业界厂商的支持。</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015222536629.png" alt="sRGB色域"></p></blockquote><h4 id="Hue-Angle色相角"><a href="#Hue-Angle色相角" class="headerlink" title="Hue Angle色相角?"></a>Hue Angle色相角?</h4><blockquote><p>孟塞尔颜色体系：</p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201014214736980.png" alt="image-20201014214736980" style="zoom:50%;"><p><strong>1）色相/色调/Hue</strong>，对于色相我们比较熟悉的是这个色环，色环上不同位置代表不同色相。色相的排列顺序是按照可见光波长从低到高，逆时针分布。这是色相环的概念。把一周均分成五5种主色互相调和成五种中间色，相邻的两个位置之间再均分10份，共100份</p><p><img src="/fu-se-fen-ji-yu-xi-tong/image-20201015221249004.png" alt="色相带"></p><p><strong>2）明度/Value/Lightness</strong>，很容易理解，就是一个颜色中含有白和黑的比例：白越多黑越少，这个颜色的明度就越高。</p><p><strong>3）色度chroma</strong>。是一个颜色里面含有这个色相的浓度。<strong>很多人容易把饱和度和明度的概念混淆。是因为他们不理解饱和度和明度在色彩空间中的位置。明度在色彩空间中的位置是从顶部到底部，明度从高到低。而饱和度在色彩空间中的位置是从里到外，饱和度从低到高。</strong></p></blockquote><h4 id="色度-色域？"><a href="#色度-色域？" class="headerlink" title="色度?色域？"></a>色度?色域？</h4><p>研究颜色测量的学科叫做<strong>色度学</strong>，色度学的任务就是用数量化来表征色觉特性。色度”中的“度”是度量的意思。 类似于长度，高度等等概念。度量长度或高度使用的工具是尺子，而度量颜色的工具就是<strong>颜色感知三要素</strong>。</p><p><strong>色域</strong>是对一种颜色进行编码的方法，也指一个技术系统能够产生的颜色的总合。在计算机图形处理中，色域是<strong>颜色的某个完全的子集</strong>。颜色子集最常见的应用是用来精确地代表一种给定的情况。例如一个给定的色彩空间或是某个输出装置的呈色范围。</p><h3 id="Figure"><a href="#Figure" class="headerlink" title="Figure"></a>Figure</h3><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h2 id="小实验"><a href="#小实验" class="headerlink" title="小实验"></a>小实验</h2><blockquote><p>MATLAB Api：<a href="https://www.mathworks.com/help/">https://www.mathworks.com/help/</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 肤色分级 </tag>
            
            <tag> 颜色空间 </tag>
            
            <tag> MATLAB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mendeley使用问题</title>
      <link href="mendeley-shi-yong-wen-ti/"/>
      <url>mendeley-shi-yong-wen-ti/</url>
      
        <content type="html"><![CDATA[<h2 id="文献引用信息有误"><a href="#文献引用信息有误" class="headerlink" title="文献引用信息有误"></a>文献引用信息有误</h2><blockquote><p>进入Mendeley网站，搜索出错的文献，然后“+Add to library”</p></blockquote><img src="/mendeley-shi-yong-wen-ti/image-20201012160759194.png" alt="image-20201012160759194" style="zoom:67%;"><blockquote><p>回到Mendeley sync一下，出现该项，但是此时无法打开，如下图将你的论文添加：</p></blockquote><p><img src="/mendeley-shi-yong-wen-ti/image-20201012160634578.png" alt="image-20201012160634578"></p><h2 id="SCI一区、二区、影响因子？"><a href="#SCI一区、二区、影响因子？" class="headerlink" title="SCI一区、二区、影响因子？"></a>SCI一区、二区、影响因子？</h2><p>一般SCI论文分四个区，一区都是国际顶级期刊，二区次之，三区和四区是一般的SCI期刊，有两种，一种是web of science的JCR（journal citation report）分区，另一种是中科院分区，请在高校或中科院内登录<a href="http://www.fenqubiao.com/">http://www.fenqubiao.com</a>。</p><p>影响因子（英文：Impact Factor），简称IF，是汤森路透（Thomson Reuters）出品的期刊引证报告（Journal Citation Reports，JCR）中的一项数据。 即某期刊前两年发表的论文在该报告年份（JCR year）中被引用总次数除以该期刊在这两年内发表的论文总数。这是一个国际上通行的期刊评价指标。影响因子现已成为国际上通用的期刊评价指标，它不仅是一种测度期刊有用性和显示度的指标，而且也是测度期刊的学术水平，乃至论文质量的重要指标。影响因子是一个相对统计量。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Typora使用问题</title>
      <link href="typora-shi-yong-wen-ti/"/>
      <url>typora-shi-yong-wen-ti/</url>
      
        <content type="html"><![CDATA[<h2 id="无序列表如何退出？"><a href="#无序列表如何退出？" class="headerlink" title="无序列表如何退出？"></a>无序列表如何退出？</h2><p>左上角的选项很迷，可以使用源代码模式退出，还可以按一下退格两下enter退出</p><h2 id="公式块编辑常见命令？"><a href="#公式块编辑常见命令？" class="headerlink" title="公式块编辑常见命令？"></a>公式块编辑常见命令？</h2><blockquote><p>版权声明：本文为博主原创文章，遵循<a href="http://creativecommons.org/licenses/by-sa/4.0/"> CC 4.0 BY-SA </a>版权协议，转载请附上原文出处链接和本声明。</p><p>本文链接：<a href="https://blog.csdn.net/mingzhuo_126/article/details/82722455">https://blog.csdn.net/mingzhuo_126/article/details/82722455</a> </p></blockquote><p>\in 属于 \notin 不属于</p><h2 id="emoji表情md编写？"><a href="#emoji表情md编写？" class="headerlink" title="emoji表情md编写？"></a>emoji表情md编写？</h2><p>参考大神博客：<a href="https://sunhwee.com/posts/a927e90e.html">https://sunhwee.com/posts/a927e90e.html</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>颜色恒常性之CCC、FCCC、Bayes</title>
      <link href="yan-se-heng-chang-xing-zhi-ccc-fccc-bayes/"/>
      <url>yan-se-heng-chang-xing-zhi-ccc-fccc-bayes/</url>
      
        <content type="html"><![CDATA[<h2 id="Bayes"><a href="#Bayes" class="headerlink" title="Bayes"></a>Bayes</h2><p>论文：A Multi-Hypothesis Approach to Color Constancy</p><h3 id="Title-amp-Abstract-amp-Conclusion"><a href="#Title-amp-Abstract-amp-Conclusion" class="headerlink" title="Title&amp;Abstract&amp;Conclusion"></a>Title&amp;Abstract&amp;Conclusion</h3><p>Multi-Hypothesis:</p><blockquote><p>假设1：</p><p>Under the prevalent assumption that the scene is illuminated by a single or dominant light source, the observed pixels of an image are typically modelled using the physical model of Lambertian image formation captured under a trichromatic photosensor</p></blockquote><p>Our likelihood estimator learns to answer <strong>a camera-agnostic question</strong> and thus enables <strong>effective multi-camera training</strong> by disentangling illuminant estimation from the supervised learning task.</p><p>learning from image samples that were <strong>captured by multiple cameras</strong></p><p>c.f.：与…相比较</p><h3 id="Figure"><a href="#Figure" class="headerlink" title="Figure"></a>Figure</h3><p>1 use an illuminant candidate set per camera</p><p>2 Each camera is <strong>encoded with a different color</strong> in (d) to highlight camera-specific illuminants.</p><p>3 [r/g,b/g]color space</p><p><img src="/yan-se-heng-chang-xing-zhi-ccc-fccc-bayes/image-20201013224250809.png" alt="(d)"></p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>$$<br>\rho_{k}(X)=\int_{\Omega}E(\lambda)S(\lambda,X)C_{k}(\lambda)d\lambda\quad\quad\quad k\in{R,G,B}<br>$$</p><p>积分是因为比如绿色，打个比方是755~760这个频段的波长共同作用生成的<br>$$<br>\rho_{k}^E=\int_{\Omega}E(\lambda)C_{k}(\lambda)d\lambda\quad\quad\quad k\in{R,G,B}<br>$$</p>]]></content>
      
      
      
        <tags>
            
            <tag> CCC </tag>
            
            <tag> FCCC </tag>
            
            <tag> Bayes </tag>
            
            <tag> CC/AWB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人脸识别与肤色分类及dlib库</title>
      <link href="ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/"/>
      <url>ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/</url>
      
        <content type="html"><![CDATA[<h2 id="人脸识别pipeline"><a href="#人脸识别pipeline" class="headerlink" title="人脸识别pipeline"></a>人脸识别pipeline</h2><p>论文参考《Modern Face Recognition with Deep Learning》，其实整篇论文与<a href="https://link.zhihu.com/?target=https://medium.com/@ageitgey?source=post_header_lockup">Adam Geitgey</a>写的文章一致，中文链接如下：<a href="https://zhuanlan.zhihu.com/p/24567586">https://zhuanlan.zhihu.com/p/24567586</a></p><h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-0.png" alt="人脸识别流程图" style="zoom:67%;"><h3 id="Step-1-arrow-heading-down-：人脸检测-Face-Detection"><a href="#Step-1-arrow-heading-down-：人脸检测-Face-Detection" class="headerlink" title="Step 1:arrow_heading_down:：人脸检测-Face Detection"></a>Step 1<span class="github-emoji"><span>⤵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2935.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>：人脸检测-Face Detection</h3><blockquote><p>​    我们使用方向梯度直方图(HOG)来标定人脸位置。</p><p>​    要在一张图片中找到脸，我们首先将图像转换为黑白，因为我们并不需要颜色数据来找到脸。</p><p>​    然后，我们将查看图片中的每一个像素。 对于单个像素，我们也要查看它周围的其他像素。我们的目标是找出并比较当前像素与直接围绕它的像素的深度。 然后我们要画一个箭头来代表图像变暗的方向，对图片中的每一个像素重复这个过程，最终每个像素会被一个箭头取代。这些箭头被称为梯度（gradients），它们能显示出图像上从明亮到黑暗的流动过程。</p><p>​    为了获取更泛化的特征，将图像分隔成16x16的小方块，统计每个主方向上有多少个梯度，最后用梯度最多的主方向代替原来小方块。<br>HOG主要优点就是减轻了图像明暗度的影响，获得的是像素之间的相对特征。</p></blockquote><p><strong>代码注意：</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#dlib  get_frontal_face_detector():生成HOG面部检测器 detector(image,1)1表示采样次数，越大识别出来的脸越多，小脸也能识别到，上采样也就是图像放大倍数</span><span class="token comment" spellcheck="true">#dlib.image_window：a gui window that can show image  win.set_image(image) </span><span class="token comment" spellcheck="true">#win.add_overlay(dlib.dlib.rectangle)：Add a list of rectangles to the image_window. They will be displayed as red boxes by default, but the color can be passed.</span><span class="token comment" spellcheck="true">#from skimage import io   io.imread()存储的图片是&lt;class 'ndarray'&gt;</span><span class="token comment" spellcheck="true">#'&amp;#123;&amp;#125;'.format 注意使用</span><span class="token comment" spellcheck="true">#enumrate    for i,data in enumerate():</span></code></pre><p><strong>图片示例：</strong></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014155202049.png" alt="Figure 1：一张人脸示例"></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014155225990.png" alt="Figure 2：HOG标定人脸位置示例"></p><h3 id="Step-II-arrow-heading-down-：人脸对齐-Face-Alignment"><a href="#Step-II-arrow-heading-down-：人脸对齐-Face-Alignment" class="headerlink" title="Step II:arrow_heading_down:：人脸对齐-Face Alignment"></a>Step II<span class="github-emoji"><span>⤵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2935.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>：人脸对齐-Face Alignment</h3><blockquote><p>把图片中的脸部分离出来之后，我们将试图扭曲每个图片，使得眼睛和嘴唇总是在图像中的样本位置（sample place）。 这将使我们在接下来的步骤中，更容易比较脸部之间的不同。这被称为人脸对齐任务。</p><p>我们使用一种称为面部特征点估计(face landmark estimation)的算法(使用由 瓦希德·卡奇米Vahid Kazemi和约瑟菲娜·沙利文Josephine Sullivan在2014 年发明的方法)。</p><p>这一算法的基本思路是找到 68 个人脸上普遍存在的特定点（称为特征点， landmarks）——包括下巴的顶部、每只眼睛的外部轮廓、每条眉毛的内部轮廓等。</p><p>获得眼睛和嘴巴的位置后，我们使用仿射变换使得眼睛和嘴巴向中间挪动到大致相同的位置，这将使我们的下一步更加准确。</p></blockquote><p><strong>tips：</strong></p><blockquote><p>将试图扭曲每个图片，使得眼睛和嘴唇总是在图像中的样本位置（sample place）</p><p>face landmark estimation:68 landmarks</p><p>旋转、缩放和错切(shear mapping)</p></blockquote><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-1.png" alt="shear mapping"></p><blockquote><p>水平错切：</p><p>Affine transformation：仿射变换，简单来说就是：一个能保持线和平行但是不保持距离和角度的几何变换(维基百科：<a href="https://en.wikipedia.org/wiki/Affine_transformation">https://en.wikipedia.org/wiki/Affine_transformation</a>)</p></blockquote><p><strong>代码注意：</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#_init_(*args, **kwargs)  *args:*args 用来将参数打包成tuple给函数体调用    **kwargs: **kwargs 打包关键字参数成dict给函数体调用</span><span class="token keyword">def</span> <span class="token function">function</span><span class="token punctuation">(</span>arg<span class="token punctuation">,</span><span class="token operator">*</span>args<span class="token punctuation">,</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>arg<span class="token punctuation">,</span><span class="token operator">*</span>args<span class="token punctuation">,</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>function<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span>a<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>b<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#dlib.shape_predictor(predictor_model)   Loads a shape_predictor from a file that contains the output of the train_shape_predictor() routine.</span><span class="token comment" spellcheck="true">#pose_predictor(image, face_rect)   #__call__(self: dlib.shape_predictor, image: array, box: dlib.rectangle) → dlib.full_object_detection</span><span class="token comment" spellcheck="true">#dlib.full_object_detection:This object represents the location of an object in an image along with the positions of each of its constituent parts  </span>  <span class="token comment" spellcheck="true">#__init__(self: dlib.full_object_detection, rect: dlib.rectangle, parts: object) → None </span>        <span class="token comment" spellcheck="true">#rect: dlib rectangle</span>        <span class="token comment" spellcheck="true">#parts: list of dlib.point, or a dlib.points object</span></code></pre><p><strong>图片示例:</strong></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014160336556.png" alt="Figure 3：68个特征点位置"></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014160355457.png" alt="Figure 4：对齐示例"></p><h3 id="Step-3-arrow-heading-down-面部编码-Face-Encoding"><a href="#Step-3-arrow-heading-down-面部编码-Face-Encoding" class="headerlink" title="Step 3:arrow_heading_down::面部编码-Face Encoding"></a>Step 3<span class="github-emoji"><span>⤵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2935.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>:面部编码-Face Encoding</h3><blockquote><p>我们利用resnet网络对大量人脸图片进行训练，每次训练要观察三个不同的脸部图像：1. 加载一张已知的人的面部训练图像;2. 加载同一个人的另一张照片;3. 加载另外一个人的照片。该网络最终可获得对人脸的128维特征值。</p></blockquote><p><strong>tips:</strong></p><blockquote><p>未知图片和已知图片循环比对，最简单但是数据量过大时太慢，不现实</p></blockquote><p><strong>图片示例</strong>:</p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201014161438279.png" alt="训练示例"></p><h3 id="Step-4-arrow-heading-down-肤色分类-Race-Classification"><a href="#Step-4-arrow-heading-down-肤色分类-Race-Classification" class="headerlink" title="Step 4:arrow_heading_down::肤色分类-Race Classification"></a>Step 4<span class="github-emoji"><span>⤵</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2935.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>:肤色分类-Race Classification</h3><blockquote><p>​    利用前面获得resnet网络模型，对LFWA+数据集的所有图片进行编码，利用简单的MLP(多层感知器),对所有编码进行训练，然后可以根据MLP对不同图片进行肤色分类，肤色分为三个等级，分别为Asian、White、Black。</p></blockquote><h2 id="相关库学习："><a href="#相关库学习：" class="headerlink" title="相关库学习："></a>相关库学习：</h2><p><strong>库地址：</strong></p><blockquote><p>gender&amp;face classification：<a href="https://github.com/wondonghyeon/face-classification">https://github.com/wondonghyeon/face-classification</a></p><p>face_recognition：<a href="https://github.com/ageitgey/face_recognition/">https://github.com/ageitgey/face_recognition/</a></p><p>dlib ：<a href="http://dlib.net/python/index.html">http://dlib.net/python/index.html</a> Python Api</p></blockquote><h3 id="face-recognition库"><a href="#face-recognition库" class="headerlink" title="face_recognition库"></a>face_recognition库</h3><p><strong>代码注意：</strong></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#face_recognition api:https://github.com/ageitgey/face_recognition/blob/55b5c136292dcd4a1f5953f3eb3181235086efab/face_recognition/api.py#L92</span><span class="token comment" spellcheck="true">#基本就是对dlib库进行了再封装，用的方法也就是以上人脸识别pipeline的过程</span><span class="token comment" spellcheck="true">#compute_face_descriptor(self: dlib.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),uint8], face: dlib.full_object_detection, num_jitters: int=0L, padding: float=0.25) -&gt; dlib.vector</span><span class="token comment" spellcheck="true">#Takes an image and a full_object_detection that references a face in that image and converts it into a 128D face descriptor. If num_jitters&gt;1 then each face will be randomly jittered slightly num_jitters times, each run through the 128D projection, and the average used as the face descriptor. Optionally allows to override default padding of 0.25 around the face.</span></code></pre><h3 id="gender-amp-face-classification"><a href="#gender-amp-face-classification" class="headerlink" title="gender&amp;face classification"></a>gender&amp;face classification</h3><p><strong>tips:</strong></p><blockquote><p>代码基本就是调的face_recognition库，face_recognition库又是封装的dlib库</p><p>最关键的是使用的数据集LFWA+，73分类</p><p>128维特征值，使用的模型是dlib_face_recognition_resnet_model_v1.dat <a href="https://github.com/ageitgey/face_recognition_models/tree/master/face_recognition_models/models">https://github.com/ageitgey/face_recognition_models/tree/master/face_recognition_models/models</a> ，该模型是dlib使用resnet训练生成的</p></blockquote><p><strong>图片示例:</strong></p><p><img src="/ren-lian-shi-bie-yu-fu-se-fen-lei-ji-dlib-ku/image-20201012212241700.png" alt="image-20201012212241700"></p><h2 id="GUI编写"><a href="#GUI编写" class="headerlink" title="GUI编写"></a>GUI编写</h2><h3 id="tkinter"><a href="#tkinter" class="headerlink" title="tkinter"></a>tkinter</h3><blockquote><p>大神博客：<a href="https://sunhwee.com/posts/80fa3a85.html#toc-heading-15">https://sunhwee.com/posts/80fa3a85.html#toc-heading-15</a></p><p>API(推荐)：<a href="https://web.archive.org/web/20190524140835/https://infohost.nmt.edu/tcc/help/pubs/tkinter/web/index.html">https://web.archive.org/web/20190524140835/https://infohost.nmt.edu/tcc/help/pubs/tkinter/web/index.html</a></p><p>还可以使用ttk，各种基本组件会变得更好看一点，上面api也有，</p></blockquote><h3 id="关于tkinter界面下点击按钮未响应的解决办法？"><a href="#关于tkinter界面下点击按钮未响应的解决办法？" class="headerlink" title="关于tkinter界面下点击按钮未响应的解决办法？"></a>关于tkinter界面下点击按钮未响应的解决办法？</h3><blockquote><p>参考：<a href="https://blog.csdn.net/aheress/article/details/105059955?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param">https://blog.csdn.net/aheress/article/details/105059955?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> face_recognition </tag>
            
            <tag> 肤色分类 </tag>
            
            <tag> tkinter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo-git-github博客搭建</title>
      <link href="hexo-git-github-bo-ke-da-jian/"/>
      <url>hexo-git-github-bo-ke-da-jian/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考：洪卫的博客教程<a href="https://sunhwee.com/posts/6e8839eb.html">https://sunhwee.com/posts/6e8839eb.html</a></p><p>参考：hexo-theme-matery主题<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md#%E9%85%8D%E7%BD%AE%E5%9F%BA%E6%9C%AC%E8%8F%9C%E5%8D%95%E5%AF%BC%E8%88%AA%E7%9A%84%E5%90%8D%E7%A7%B0%E8%B7%AF%E5%BE%84url%E5%92%8C%E5%9B%BE%E6%A0%87icon">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md#%E9%85%8D%E7%BD%AE%E5%9F%BA%E6%9C%AC%E8%8F%9C%E5%8D%95%E5%AF%BC%E8%88%AA%E7%9A%84%E5%90%8D%E7%A7%B0%E8%B7%AF%E5%BE%84url%E5%92%8C%E5%9B%BE%E6%A0%87icon</a></p></blockquote><h2 id="按流程搭建遇到的问题："><a href="#按流程搭建遇到的问题：" class="headerlink" title="按流程搭建遇到的问题："></a>按流程搭建遇到的问题：</h2><h3 id="搭建hexo博客时，到了最后一步，hexo-s后只出现代码，而不是首页？"><a href="#搭建hexo博客时，到了最后一步，hexo-s后只出现代码，而不是首页？" class="headerlink" title="搭建hexo博客时，到了最后一步，hexo s后只出现代码，而不是首页？"></a>搭建hexo博客时，到了最后一步，hexo s后只出现代码，而不是首页？</h3><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012224004113.png" alt="错误代码"></p><p><strong>在npm install安装依赖时出现了错误</strong></p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012224051241.png" alt="错误为第10行"></p><p>仔细查看错误信息，我们不难发现是ejs出现了问题。我们可以先执行以下代码后再继续后续操作。</p><pre><code>npm install ejs@2.7.4 --ignore-scripts</code></pre><p><strong><em>注意：之后所有的Bash命令都在最后一个MyBlog文件夹下操作，也就是你之前安装hexo那个文件夹！</em></strong></p><h3 id="什么是github-io？"><a href="#什么是github-io？" class="headerlink" title="什么是github.io？"></a>什么是github.io？</h3><blockquote><p>官网的一句话来形容 Websites for you and your projects</p></blockquote><h3 id="购买个人域名之后打开失败？"><a href="#购买个人域名之后打开失败？" class="headerlink" title="购买个人域名之后打开失败？"></a>购买个人域名之后打开失败？</h3><blockquote><p>极有可能是你未设置域名解析！</p></blockquote><h3 id="写文章发布文章不生成文件夹及图片无法显示？"><a href="#写文章发布文章不生成文件夹及图片无法显示？" class="headerlink" title="写文章发布文章不生成文件夹及图片无法显示？"></a>写文章发布文章不生成文件夹及图片无法显示？</h3><h4 id="不生成文件夹？"><a href="#不生成文件夹？" class="headerlink" title="不生成文件夹？"></a>不生成文件夹？</h4><p>首先，新建博客一定要用hexo new post命令，不然很多信息识别不出来</p><p>然后将_config.yml文件中的post asset folder设置为true，之后会出现文件夹</p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012224940500.png" alt="设置为true"></p><h4 id="图片不显示？"><a href="#图片不显示？" class="headerlink" title="图片不显示？"></a>图片不显示？</h4><p>首先下载依赖</p><pre><code>npm install hexo-asset-image --save</code></pre><p>然后对于typora编辑，偏好设置为：</p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012225346785.png" alt="image-20201012225346785" style="zoom: 80%;"><p>然后图片编写时，使用相对路径，例如：</p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201012225527582.png" alt="例子"></p><p><strong><em>另外注意：千万不要错误使用转义符’\‘!!!!</em></strong></p><h3 id="数学公式块无法正常显示？"><a href="#数学公式块无法正常显示？" class="headerlink" title="数学公式块无法正常显示？"></a>数学公式块无法正常显示？</h3><blockquote><p>后面配置了主题就可以了！</p><p>但是注意：<strong>数学公式中如果出现了连续两个{，中间一定要加空格！</strong></p></blockquote><h3 id="菜单导航配置在哪？"><a href="#菜单导航配置在哪？" class="headerlink" title="菜单导航配置在哪？"></a>菜单导航配置在哪？</h3><blockquote><p>菜单导航配置在themes/hexo-theme-matert/__config.yml</p></blockquote><h3 id="什么是RSS订阅？"><a href="#什么是RSS订阅？" class="headerlink" title="什么是RSS订阅？"></a>什么是RSS订阅？</h3><blockquote><p>​        RSS也称为RSS订阅或RSS提要，博客和新闻网站的一个常见做法是联合其内容。Web联合是指来自网站的内容可供其他站点或远程应用程序使用。Web联合的最常用方法是使用称为<strong>ReallySimpleSyndication</strong>的协议。RSS是一种协议，允许网站将其内容或其部分内容提供给其他网站或应用程序。</p></blockquote><h3 id="DaoVoice"><a href="#DaoVoice" class="headerlink" title="DaoVoice?"></a>DaoVoice?</h3><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013144940429.png" alt="设置"></p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013144951426.png" alt="设置"></p><h3 id="新建文章模板修改失败？"><a href="#新建文章模板修改失败？" class="headerlink" title="新建文章模板修改失败？"></a>新建文章模板修改失败？</h3><blockquote><p>莫名其妙post.md上下都变成了两个—，奇怪</p></blockquote><h3 id="修改页脚"><a href="#修改页脚" class="headerlink" title="修改页脚?"></a>修改页脚?</h3><h3 id="修改社交链接？"><a href="#修改社交链接？" class="headerlink" title="修改社交链接？"></a>修改社交链接？</h3><h3 id="不蒜子？不蒜子访问量和人数无法区分问题？"><a href="#不蒜子？不蒜子访问量和人数无法区分问题？" class="headerlink" title="不蒜子？不蒜子访问量和人数无法区分问题？"></a>不蒜子？不蒜子访问量和人数无法区分问题？</h3><blockquote><p>是一个极简网页计数器</p></blockquote><h3 id="添加动漫人物"><a href="#添加动漫人物" class="headerlink" title="添加动漫人物?"></a>添加动漫人物?</h3><blockquote><p>由于一直要安包，不敢继续弄了</p></blockquote><h3 id="gitalk-error-not-found？"><a href="#gitalk-error-not-found？" class="headerlink" title="gitalk error not found？"></a>gitalk error not found？</h3><blockquote><p>既有可能是yml的设置错误！</p><p><strong>owner和admin都填写github用户名</strong>，<strong>repo填我们的博客github仓库名</strong></p></blockquote><h3 id="yml、yaml格式不正确？"><a href="#yml、yaml格式不正确？" class="headerlink" title="yml、yaml格式不正确？"></a>yml、yaml格式不正确？</h3><blockquote><p>使用这个在线校验器校验：<a href="http://www.bejson.com/validators/yaml_editor/">http://www.bejson.com/validators/yaml_editor/</a></p></blockquote><h3 id="gitalk未找到相关issues？"><a href="#gitalk未找到相关issues？" class="headerlink" title="gitalk未找到相关issues？"></a>gitalk未找到相关issues？</h3><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013183732541.png" alt="URL"></p><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013183843079.png" alt="回调函数"></p><blockquote><p>一定要<strong>使用https而不是http</strong></p><p>还是不行？？？</p><p>失败！</p></blockquote><h3 id="樱花飘落？"><a href="#樱花飘落？" class="headerlink" title="樱花飘落？"></a>樱花飘落？</h3><blockquote><p>暂时配置失败！</p></blockquote><h3 id="网站根目录在哪里？"><a href="#网站根目录在哪里？" class="headerlink" title="网站根目录在哪里？"></a>网站根目录在哪里？</h3><p><img src="/hexo-git-github-bo-ke-da-jian/image-20201013200031772.png" alt="网站根目录"></p><h2 id="git学习"><a href="#git学习" class="headerlink" title="git学习:"></a>git学习:</h2><blockquote><p>廖雪峰git教程 <a href="https://www.liaoxuefeng.com/wiki/896043488029600">https://www.liaoxuefeng.com/wiki/896043488029600</a></p></blockquote><ul><li>git-世界上目前最先进的分布式版本控制系统，结束了手动管理多个“版本”的史前时代，进入到版本控制的20世纪</li><li>Linus花了两周时间自己用C写了一个分布式版本控制系统，这就是Git！</li><li>集中式和分布式版本控制系统：</li><li>集中式版本控制系统，版本库是集中存放在中央服务器的</li><li>分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，分布式版本控制系统通常也有一台充当“中央服务器”的电脑，但这个服务器的作用仅仅是用来方便“交换”大家的修改，没有它大家也一样干活，只是交换修改不方便而已。</li><li>windows 使用git bash来敲命令行</li></ul><h2 id="ejs学习："><a href="#ejs学习：" class="headerlink" title="ejs学习："></a>ejs学习：</h2>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> git </tag>
            
            <tag> ejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="hello-world/"/>
      <url>hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
